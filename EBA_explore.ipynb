{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathan/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from get_weather_data import convert_isd_to_df, convert_state_isd\n",
    "\n",
    "pi=np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with Mahlon Sweet Field\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with Salem Municipal Airport/McNary Field\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with Portland International Airport\n"
     ]
    }
   ],
   "source": [
    "air_df = pd.read_csv('data/air_code_df.gz')\n",
    "\n",
    "#Just get the weather station data for cities in Oregon.\n",
    "df_weather=convert_state_isd(air_df,'OR')\n",
    "\n",
    "#Read all of the weather data in.\n",
    "#df_weather=pd.read_csv('data/airport_weather.gz',index_col=0,parse_dates=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#load electricity data\n",
    "df_eba=pd.read_csv('data/EBA_time.gz',index_col=0,parse_dates=True)\n",
    "#df_region_eba=pd.read_csv('data/EBA_region_time.gz',index_col=0,parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Select temperature for Portland, OR\n",
    "msk1=np.array(df_weather['city']=='Portland')\n",
    "msk2=np.array(df_weather['state']=='OR')\n",
    "\n",
    "df_pdx_weath=df_weather.loc[msk1&msk2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#get electricity data for Portland General Electric\n",
    "msk=df_eba.columns.str.contains('Portland')\n",
    "df_pdx=df_eba.loc[:,msk]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Anomaly Detection\n",
    "\n",
    "A quick look at the portland data suggests that there are both real outliers, and ones from errors in the data process (100x surrounding values).  \n",
    "\n",
    "Tests should be for total interchange = 0, and \n",
    "Demand=Net Gen - Net Interchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbc24a8668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7efbc2340b70>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnew=[735567.85,736564,0,10000]\n",
    "fig=plt.figure(figsize=(15,6))\n",
    "ax = fig.add_axes([0.1, 0.1, 0.6, 0.75])\n",
    "ax.plot(df_pdx)\n",
    "ax.legend(df_pdx.columns.values,loc='upper left',bbox_to_anchor=(1,1),prop={'size':9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Check that the energy is balanced for this small subset: Demand = Net Generation - Net Interchange.\n",
    "#Seems to not be true.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efba1317400>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb9f648a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dem=df_pdx.iloc[:,0]\n",
    "gen=df_pdx.iloc[:,2]\n",
    "net=df_pdx.iloc[:,3]\n",
    "plt.figure()\n",
    "plt.plot(dem-(-gen+net),'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The data in later 2015 seem pretty crappy.  Looking at the EBA user notes, this seems to be a common complaint.\n",
    "The other errors seem to involve some anomalous zero points in the temperature series.  For temperature series where huge swings are unlikely\n",
    "it may be feasible to replace anomalous 0 values with the average of the neighbouring points.  In case of actual zero values, this shouldn't be a large problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Make a combined Portland Dataframe for demand vs weather.\n",
    "dem=df_pdx.iloc[:,0]\n",
    "df_joint=pd.DataFrame(dem)\n",
    "df_joint=df_joint.join(df_pdx_weath)\n",
    "df_joint.head()\n",
    "#plt.figure()\n",
    "x=df_joint.iloc[:,0]\n",
    "y=df_joint.iloc[:,1]\n",
    "df_joint['TempShift']=150+abs(df_joint['Temp']-150)\n",
    "df_joint=df_joint.rename(columns={df_joint.columns[0]:'Demand'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     Demand  CloudCover  DewTemp  Precip-1hr  Precip-6hr  \\\n",
       "2015-07-01 00:00:00  3648.0         2.0    144.0         0.0         NaN   \n",
       "2015-07-01 01:00:00  3658.0         0.0    150.0         0.0         NaN   \n",
       "2015-07-01 02:00:00  3608.0         0.0    156.0         0.0         NaN   \n",
       "2015-07-01 03:00:00  3493.0         0.0    156.0         0.0         NaN   \n",
       "2015-07-01 04:00:00  3374.0         0.0    150.0         0.0         NaN   \n",
       "\n",
       "                     Pressure   Temp  WindDir  WindSpeed      city  \\\n",
       "2015-07-01 00:00:00   10150.0  333.0    310.0       77.0  Portland   \n",
       "2015-07-01 01:00:00   10146.0  322.0    310.0       93.0  Portland   \n",
       "2015-07-01 02:00:00   10145.0  317.0    310.0       82.0  Portland   \n",
       "2015-07-01 03:00:00   10146.0  300.0    320.0       62.0  Portland   \n",
       "2015-07-01 04:00:00   10148.0  278.0    320.0       51.0  Portland   \n",
       "\n",
       "                      city, state     region state  TempShift  \n",
       "2015-07-01 00:00:00  Portland, OR  Northwest    OR      333.0  \n",
       "2015-07-01 01:00:00  Portland, OR  Northwest    OR      322.0  \n",
       "2015-07-01 02:00:00  Portland, OR  Northwest    OR      317.0  \n",
       "2015-07-01 03:00:00  Portland, OR  Northwest    OR      300.0  \n",
       "2015-07-01 04:00:00  Portland, OR  Northwest    OR      278.0  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_joint.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff7cfc3b438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Energy Usage vs Temperature in Portland, OR')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(df_joint['Temp'],df_joint.iloc[:,0],'rx')\n",
    "plt.ylabel('Hourly Demand (kWh)')\n",
    "plt.xlabel('Temperature (Celcius x10)')\n",
    "plt.title('Energy Usage vs Temperature in Portland, OR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbb9752ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Energy Usage vs Temperature in Portland, OR')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(df_joint['WindSpeed'],df_joint.iloc[:,0],'rx')\n",
    "plt.xlabel('Wind Speed (m/s x10)')\n",
    "plt.ylabel('Hourly Demand (kWh)')\n",
    "plt.title('Energy Usage vs Temperature in Portland, OR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbb98c6f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Energy Usage vs Precipitation in Portland, OR')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(df_joint['Precip-1hr'],df_joint.iloc[:,0],'rx')\n",
    "plt.ylabel('Demand (kWh)')\n",
    "plt.xlabel('Precipitation (mm x 10)')\n",
    "plt.title('Energy Usage vs Precipitation in Portland, OR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So the scatterplot for temperature versus demand shows a clear (expected) trend as the tempererature becomes excessively hot or cold.\n",
    "It looks like two blobs with similar slopes for deviations from 15 Celcius.  You can also see anomalous values at zero,\n",
    "and extremely high values.  I'm skeptical of the 9000kWh value?\n",
    "\n",
    "Let's also plot the correlation matrix across the whole time series.  Evidently a temperature  deviation from 15 celcius shows the largest correlation, with wind speed being the next most important.\n",
    "I know the coldest temperatures in some places emerge in inversions (with absolutely no air movement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "My naive model for how energy usage would vary is a factor for deviation from some ideal temperature, as well as daily and yearly oscillations.\n",
    "\\begin{equation}\n",
    "    \\text{Demand}= A_0+A_T|T-T_0|+A_\\text{day}\\sin\\left( \\frac{2\\pi t}{24}+\\phi_{\\text{day}}\\right)+A_\\text{year}\\sin\\left(\\frac{2\\pi d}{365}+\\phi_{\\text{year}}\\right)\n",
    "\\end{equation}\n",
    "where $t$ is the hour of the day in 24 hour time, and $d$ is the number of days since the start of the year.\n",
    "\n",
    "To get a sense of those oscillations, let's look at the autocorrelation function for demand, as a function of time.  (Alternatively, the power spectrum?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Removing Extremes\n",
    "\n",
    "Lets try to clean up some of this data.\n",
    "My strategy is to find missing (or zero values) or excessive data.  Find values larger than 3x standard deviations from the mean.\n",
    "Those extreme values are replaced with the mean of the two neighbouring points.\n",
    "This is also carried out for points with zero. Under the assumption that the data are otherwise continuous, the smoothing should not be a large distortion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def avg_extremes(df,window=2):\n",
    "    \"\"\"avg_extremes(df)\n",
    "    Replace extreme outliers, or zero values with the average on either side.\n",
    "    Suitable for occasional anomalous readings.\n",
    "    \"\"\"\n",
    "    mu=df.mean()\n",
    "    sd=df.std()\n",
    "    msk1=(df-mu)>4*sd\n",
    "    msk2 = df==0\n",
    "    msk=msk1|msk2\n",
    "    print( \"Number of extreme values {}. Number of zero values {}\".format(sum(msk1),sum(msk2)))\n",
    "    ind= np.arange(len(df))[msk]\n",
    "    for i in ind:\n",
    "        df.iloc[i]=(df.iloc[i-window]+df.iloc[i-window])/2\n",
    "\n",
    "    return df\n",
    "\n",
    "def remove_na(df,window=2):\n",
    "    \"\"\"remove_na(df)\n",
    "    Replace all NA values with the mean value of the series.\n",
    "    \"\"\"\n",
    "    na_msk=np.isnan(df.values)\n",
    "    #first pass:replace them all with the mean value - if a whole day is missing.\n",
    "    df[na_msk]=df.mean()\n",
    "\n",
    "    ind= np.arange(len(df))[na_msk]\n",
    "    #for isolated values, replace by the average on either side.    \n",
    "    for i in ind:\n",
    "        df.iloc[i]=(df.iloc[i-window]+df.iloc[i-window])/2\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Auto regressive modelling\n",
    "\n",
    "A popular approach assumes that the current demand is probably the same as the previous demand, with some noise.\n",
    "This is the auto-regressive, integrated, moving average (ARIMA) class of models that are popular linear models within econometric forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def make_seasonal_plots(dem,temp,per,nlags):\n",
    "    \"\"\"Make seasonal decomposition of temperature, and demand curves.\n",
    "    Plots those decompositions, and their correlation/autocorrelation plots.\n",
    "    dem- input demand series\n",
    "    temp-input temperature series\n",
    "    per - input date to index on for plotting, e.g. '2016-03'\n",
    "    nlags - number of lags for correlation plots.\n",
    "    \"\"\"\n",
    "    #Carry out the \"demand\" and \"temperature\" seasonal decompositions.\n",
    "    dem_decomposition = seasonal_decompose(dem,two_sided=False)\n",
    "    dem_mu=dem.mean()\n",
    "    dem_trend = dem_decomposition.trend/dem_mu  #Find rolling average over most important period.\n",
    "    dem_seasonal = dem_decomposition.seasonal/dem_mu  #Find the dominant frequency components\n",
    "    dem_residual = dem_decomposition.resid/dem_mu  #Whatever is left.\n",
    "\n",
    "    temp_decomposition = seasonal_decompose(temp,two_sided=False)\n",
    "    temp_mu=temp.mean()\n",
    "    temp_trend = temp_decomposition.trend/temp_mu  #Find rolling average over most important period.\n",
    "    temp_seasonal = temp_decomposition.seasonal/temp_mu  #Find the dominant frequency components\n",
    "    temp_residual = temp_decomposition.resid/temp_mu  #Whatever is left.\n",
    "\n",
    "    #Plot out the decompositions\n",
    "    plt.figure(figsize=(15,9))\n",
    "    plt.title('Normalized Seasonal Decomposition')\n",
    "    plt.subplot(411)\n",
    "    plt.plot(dem_trend[per],'b',temp_trend[per],'k')\n",
    "    plt.ylabel('Trend')\n",
    "    plt.subplot(412)\n",
    "    plt.plot(dem_seasonal[per],'b',temp_seasonal[per],'k')\n",
    "    plt.ylabel('Seasonal Oscillation')\n",
    "    plt.subplot(413)\n",
    "    plt.plot(dem_residual[per],'b',temp_residual[per],'k')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.subplot(414)\n",
    "    plt.plot(dem[per]/dem_mu,'b',temp[per]/temp_mu,'k')\n",
    "    plt.ylabel('Data')\n",
    "    plt.show()\n",
    "\n",
    "    #Plot the auto-correlation plots.\n",
    "    nlags=np.min([len(dem[per])-1,nlags,len(temp[per])-1])\n",
    "    print('Nlags',nlags)\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plot_acf(temp_residual[per],'b-x','Temp Residual',nl=nlags)\n",
    "    plot_acf(dem_residual[per],'r-+','Demand Residual',nl=nlags)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plot_acf(temp[per],'b-x','Temp',nl=nlags)\n",
    "    plot_acf(dem[per],'r-+','Demand',nl=nlags)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return None\n",
    "\n",
    "def plot_acf(ts,ls,line_label,nl=50):\n",
    "    \"\"\"plot_acf(ts,ls,nl)\n",
    "    Plot the auto-correlation plots for a timeseries (ts) up to a given number of lags (nl)\n",
    "    Give a specific linestyle (ls), and label.\n",
    "    \"\"\"\n",
    "    #Actually do those auto-corellations, on the series, and its absolute value.\n",
    "    lag_acf = acf(ts,nlags=nl)\n",
    "    lag_pacf=pacf(ts,nlags=nl,method='ols')\n",
    "    #5% confidence intervals.\n",
    "    sd = 1.96/np.sqrt(len(ts))\n",
    "    #Make some purty subplots.\n",
    "    plt.subplot(121)\n",
    "    plt.ylabel('Auto Correlation')\n",
    "    plt.plot(lag_acf,ls,label=line_label)\n",
    "    plt.axhline(y=sd,color='gray')\n",
    "    plt.axhline(y=-sd,color='gray')\n",
    "    plt.ylabel('Auto Correlation')\n",
    "    plt.xlabel('Lag')\n",
    "    plt.subplot(122)\n",
    "    plt.ylabel('Partial Auto Correlation')\n",
    "    plt.xlabel('Lag')\n",
    "    plt.axhline(y=sd,color='gray')\n",
    "    plt.axhline(y=-sd,color='gray')\n",
    "    plt.plot(lag_pacf,ls,label=line_label)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff7b438be80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff7b43d7940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathan/anaconda3/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:106: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nlags 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff7cf9a2f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extreme values 0. Number of zero values 148\n",
      "(JBM) Freq is  24\n",
      "(JBM) Freq is  24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extreme values 1. Number of zero values 3\n"
     ]
    }
   ],
   "source": [
    "dem=df_joint['Demand'].asfreq('H')\n",
    "dem=avg_extremes(dem)\n",
    "dem=remove_na(dem)\n",
    "\n",
    "temp=df_joint['Temp'].asfreq('H')\n",
    "temp=avg_extremes(temp)\n",
    "temp=remove_na(temp)\n",
    "\n",
    "make_seasonal_plots(dem,temp,'2016-01',50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Evidently, this finds the day timescale.  I'm a bit skeptical of these plots, and this approach (trying simple seasonality reduction on the whole data set at once).  I think the seasonal component has not been completely removed.\n",
    "The \"seasonal_decompose\" method works by estimating the frequency of the data.  The trend is found by taking averages within each period, and the seasonality is found by averages over multiple periods.  The remainder once these are subtracted is the \"noise\" process.\n",
    "\n",
    "There is an additional year-long oscillations are still buried in the trend.  Of course, this data has only two years worth of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test statistic -1.28011239076\n",
      "p-value 0.638221098471\n",
      "#Lags 20\n",
      "Num observed 699\n",
      "Critical Values {'1%': -3.4397398095543279, '5%': -2.8656836898038098, '10%': -2.5689766074363334}\n"
     ]
    }
   ],
   "source": [
    "#Do some tests for stationarity\n",
    "ad_results=adfuller(dem['2016-11'],autolag='BIC')\n",
    "names=[\"Test statistic\",\"p-value\",\"#Lags\",\"Num observed\",\"Critical Values\"]\n",
    "\n",
    "for i in range(0,5):\n",
    "    print( names[i],ad_results[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The above plot is the raw auto-correlation between the demand and temperature.  I think there is a substantive daily oscillation left by the naive seasonal approach.  This assumes a single oscillation, repeated for all cases.  In this data however, there is a clear daily signal, which it picks out.  However, this will vary over the course of the year.\n",
    "\n",
    "Diebold's text \"Elements of Forecasting\" suggests putting in dummy variables for seasonality.  So hour of day, and day of year.  The resulting series.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff7b4224978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff7a3ba7940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathan/anaconda3/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:106: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nlags 30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff7a3b44a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extreme values 7. Number of zero values 0\n",
      "Number of extreme values 0. Number of zero values 5\n",
      "(JBM) Freq is  7\n",
      "(JBM) Freq is  7\n"
     ]
    }
   ],
   "source": [
    "#Compare series at noon\n",
    "msk=df_joint.index.hour==12\n",
    "\n",
    "dem=df_joint[msk]['Demand'].asfreq('D')\n",
    "dem=avg_extremes(dem)\n",
    "dem=remove_na(dem)\n",
    "\n",
    "temp=df_joint[msk]['Temp'].asfreq('D')\n",
    "temp=avg_extremes(temp)\n",
    "temp=remove_na(temp)\n",
    "make_seasonal_plots(dem,temp,'2016-03',40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "So looking at just an hour of the day, the seasonal split manages to work fairly well at making the residual series a stationary one.\n",
    "The \"trend\" is effectively picking out the anticipated annual shifts, and the \"seasonality\" is pulling out a small week long oscillation (the amplitude is much smaller than the trend).  The residuals also seem to be stationary now.  \n",
    "\n",
    "The autocorrelation plots also show some oscillations (I think the seasonal reduction is pretty crap), but here they decay to within error after\n",
    "6 days.  \n",
    "The raw demand auto-correlations might be showing annual oscillations in temperature and electricity usage that would get stronger from 120-240 days.\n",
    "\n",
    "Turns out the \"seasonal\" part \n",
    "\n",
    "If we look at the correlation plots for various hours there are a couple clear trends.  Looking at 6pm, shows a really clear weekly (7 day) signal.  This is not as obvious at other times of day (6am, 9am, 12pm).  Note that I have not selected out weekends, or holidays here.  Weekends might be strongly contributing to the weekly oscillation.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Fourier Plots\n",
    "\n",
    "I'm curious about the power spectrum for this series.  I'm also unfamiliar with Python's FFT routine, so this is a good time to play around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extreme values 0. Number of zero values 0\n"
     ]
    }
   ],
   "source": [
    "#clean up the data\n",
    "dem_t=df_joint['Demand']['2015-07':'2016-06'].copy()\n",
    "dem_t=avg_extremes(dem_t)\n",
    "dem_t=remove_na(dem_t)\n",
    "dem_tv=dem_t.values\n",
    "\n",
    "\n",
    "#set up FFT time/frequency scales\n",
    "Nt = len(dem_tv)\n",
    "#scale time to days.\n",
    "Tmax = Nt/24\n",
    "dt = 1/24\n",
    "t = np.arange(0,Tmax,dt)\n",
    "df = 1/Tmax\n",
    "fmax=0.5/dt\n",
    "f = np.arange(-fmax,fmax,df)\n",
    "\n",
    "#carry out fft \n",
    "dem_f=np.fft.fftshift(dem_tv)\n",
    "dem_f=np.fft.fft(dem_f)\n",
    "dem_f=np.fft.ifftshift(dem_f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff7cdd870b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "spec=abs(dem_f)**2\n",
    "spec/=sum(spec)\n",
    "plt.semilogy(f,spec)\n",
    "fcut=1/7\n",
    "plt.axis([-10*fcut,10*fcut,1E-10,1])\n",
    "plt.xlabel('Frequency (1/day)')\n",
    "plt.ylabel('Normalized Demand Power Spectrum')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "This is a normalized power spectrum for the demand data.  You can clearly see the peaks arising from daily and weekly oscillations.\n",
    "There is a small peak at very low frequencies, which corresponds to the annual oscillation.  However, given we only have 2 years of data, this\n",
    "is almost exactly the Nyquist frequency (lowest frequency that can be resolved).  Let's examine both the high (intra-day) and low (year-long) frequency scales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The top figure, shows the low frequency (year-long) data.  The lower plot shows nearly the whole frequency spectrum.  Note the peaks at 1,2,3,etc.  These are the daily frequency oscillations.  They also share correlations with other frequencies fo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def remove_square_peak(Y,f,center,width):\n",
    "    \"\"\"remove_yearly\n",
    "    Assumes there is a yearly trend.\n",
    "    Subtracts off everything on a monthly or longer timescale. (around 1/30)\n",
    "    Replaces that with the average of the neighbouring points.\n",
    "    \n",
    "    inputs:\n",
    "    Y - initial centered Fourier transform\n",
    "    f - list of frequencies Fourier transform is evaluated a\n",
    "    shape - function to use to define the window.  Takes a position input, and width. \n",
    "    center - frequency to center filter at, to remove        \n",
    "    width - width of the filter.\n",
    "\n",
    "    return:\n",
    "    detrended -transform after subtracting off this component.  \n",
    "    trend     -the subtracted portion.\n",
    "    \"\"\" \n",
    "    #find stuff within +/- 1 width\n",
    "    trend_msk= abs(f-center)<width\n",
    "    #find stuff within +/- 1.5 widths, and not inside 1 ith\n",
    "    mean_msk = abs(f-center)<1.5*width\n",
    "    mean_msk = mean_msk & ~trend_msk\n",
    "\n",
    "    replace_avg = Y[mean_msk].mean()\n",
    "    replace_std = Y[mean_msk].std()\n",
    "    trend=np.zeros(len(f))+0j\n",
    "    trend[trend_msk] = Y[trend_msk]-replace_avg\n",
    "    detrend = Y-trend\n",
    "    return trend, detrend\n",
    "\n",
    "def remove_sinc_peak(Y,f,center,width):\n",
    "    \"\"\"remove_sinc_peak\n",
    "    Assumes there is a peak described by a sinc (fro mthe truncated FFT)\n",
    "    Tries to set the peak height based on the value of the FFT at the peaks\n",
    "    Subtracts off a sinc function with that amplitude. \n",
    "    Replaces that with the average of the neighbouring points.\n",
    "    \n",
    "    inputs:\n",
    "    Y - initial centered Fourier transform\n",
    "    f - list of frequencies Fourier transform is evaluated a\n",
    "    shape - function to use to define the window.  Takes a position input, and width. \n",
    "    center - frequency to center filter at, to remove        \n",
    "    width - width of the filter.\n",
    "\n",
    "    return:\n",
    "    detrended -transform after subtracting off this component.  \n",
    "    trend     -the subtracted portion.\n",
    "    \"\"\" \n",
    "    #find stuff within +/- 1 width\n",
    "    trend_msk= abs(f-center)<width\n",
    "    #find stuff within +/- 1.5 widths, and not inside 1 ith\n",
    "    replace_avg = Y[trend_msk].mean()\n",
    "    trend = replace_avg*sinc((f-center)/width)\n",
    "    detrend = Y-trend\n",
    "    return trend, detrend\n",
    "\n",
    "def sinc(x):\n",
    "    \"\"\"sinc(x)\n",
    "    Computes sin(x)/x, with care to take correct limit at x=0\n",
    "    \"\"\"\n",
    "    msk=(abs(x)>1E-16)\n",
    "    s=np.zeros(len(x))\n",
    "    s[~msk]=1\n",
    "    s[msk]=np.sin(x[msk])/x[msk]\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def fft_detrend(F,f,width,remove_func):\n",
    "    \"\"\"detrend(dem_f,f,width,remove_func)\n",
    "    \n",
    "    Removes mean, annual, daily and weekly trends in data\n",
    "    by filtering the FFT.\n",
    "\n",
    "    inputs:\n",
    "    F - Fourier transformed function\n",
    "    f - frequency list (assumed to be scaled so 1 = 1/day)\n",
    "    width - frequency width to apply on filter\n",
    "    remove_func - functional form of the filter.\n",
    "\n",
    "    return:\n",
    "    F_trend_tot - total trend removed\n",
    "    F_detrend   - detrended function.\n",
    "    \"\"\" \n",
    "\n",
    "    F_detrend=dem_f\n",
    "    F_trend_tot=np.zeros(len(dem_f))+0j\n",
    "\n",
    "    F_trend,F_detrend=remove_func(dem_f,f,0,width)\n",
    "    F_trend_tot+=F_trend\n",
    "    #remove daily oscillations\n",
    "    for k in [1,2]:\n",
    "        #positive peak\n",
    "        F_trend,F_detrend=remove_func(F_detrend,f,k,width)\n",
    "        F_trend_tot+=F_trend\n",
    "        #negative peak\n",
    "        F_trend,F_detrend=remove_func(F_detrend,f,-k,width)\n",
    "        F_trend_tot+=F_trend\n",
    "\n",
    "    # #remove weekly oscillations\n",
    "    for i in range(1,6):\n",
    "        f0=i/7\n",
    "        F_trend,F_detrend=remove_func(F_detrend,f,f0,width)\n",
    "        F_trend_tot+=F_trend\n",
    "        F_trend,F_detrend=remove_func(F_detrend,f,-f0,width)\n",
    "        F_trend_tot+=F_trend\n",
    "\n",
    "    return F_trend_tot,F_detrend\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5 5\n",
      "[0 1 2 3 4] [3 4 5 6 7] [ 6  7  8  9 10]\n"
     ]
    }
   ],
   "source": [
    "def moving_avg(Y,width):\n",
    "    \"\"\"moving_avg(Y, width)\n",
    "    Compute moving average by differencing the cumulative sum.\n",
    "    \"\"\"\n",
    "    Ycum = np.cumsum(Y)\n",
    "    Ysmooth=np.zeros(len(Y))+0j\n",
    "    Ysmooth[width:-width]=(Ycum[2*width:]-Ycum[:-2*width])/(2*width)\n",
    "    return Ysmooth    \n",
    "\n",
    "width=3\n",
    "n=np.arange(0,11)\n",
    "\n",
    "print(len(n[0:-2*width]),len(n[width:-width]),len(n[2*width:]))\n",
    "print((n[0:-2*width]),(n[width:-width]),(n[2*width:]))\n",
    "\n",
    "dem_f_s=moving_avg(dem_f,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff7b4101198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathan/anaconda3/lib/python3.6/site-packages/numpy/core/numeric.py:531: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "y = np.exp(-0.5*f*f)+ 0.15*np.random.randn(len(f))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(f,y,f,moving_avg(y,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "f_trend_tot,f_detrend = fft_detrend(dem_f,f,2/365,remove_square_peak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff7a3ba2128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "plt.axis([-0.2,2,1E3,1E8])\n",
    "plt.semilogy(f,abs(f_trend_tot),f,abs(f_detrend),f,abs(dem_f_s))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#check out what this detrending looks like.\n",
    "#\n",
    "def invert_fft(Y):\n",
    "    #undo the fftshifts, invert fft, and take the real part\n",
    "    y=np.fft.fftshift(Y)\n",
    "    y=np.fft.ifft(y)\n",
    "    y=np.fft.fftshift(y)\n",
    "    y=np.real(y)\n",
    "    return y\n",
    "\n",
    "t_trend=invert_fft(f_trend_tot)\n",
    "t_detrend=invert_fft(f_detrend)\n",
    "\n",
    "# t_trend=pd.Series(t_trend,index=dem_t.index)\n",
    "# t_detrend=pd.Series(t_detrend,index=dem_t.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efbb9708f60>,\n",
       " <matplotlib.lines.Line2D at 0x7efbb9708518>,\n",
       " <matplotlib.lines.Line2D at 0x7efbb9708940>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbb7caa780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "plt.plot(t,dem_t,'b',t,t_trend,'r',t,t_detrend,'g')\n",
    "#plt.axis([550,560,min(t_detrend),max(dem_t)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So that used just July/2015-June/2016 data to find the trend.  Let's now see how this does when applied to the next year's data.\n",
    "The trend can be appended to itself.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extreme values 1. Number of zero values 3\n"
     ]
    }
   ],
   "source": [
    "dem_t2=df_joint['Demand']['2015-07':'2017-06'].copy()\n",
    "dem_t2=avg_extremes(dem_t2)\n",
    "dem_t2=remove_na(dem_t2)\n",
    "\n",
    "#need to ditch a day due to leap year in 2016 elongating the year\n",
    "t_trend2=np.append(t_trend,t_trend[:-24])\n",
    "t_trend2 = pd.Series(t_trend2,index=dem_t2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efb994a5ef0>]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb99285c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "per='2016'\n",
    "plt.plot(-t_trend2[per]+dem_t2[per],'b-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dem_residual' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-f9644d8ce6e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplot_acf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_detrend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r-x'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Manually Detrended'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplot_acf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdem_residual\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'2016-01'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'b-x'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Detrended'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dem_residual' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb99e6acf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'dem_residual' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-f9644d8ce6e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplot_acf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_detrend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r-x'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Manually Detrended'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplot_acf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdem_residual\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'2016-01'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'b-x'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Detrended'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dem_residual' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "plot_acf((t_detrend),'r-x','Manually Detrended',nl=30)\n",
    "plot_acf(dem_residual['2016-01'],'b-x','Detrended',nl=30)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "So, that was a waste of time.  My manual detrend-everything-at-once approach seems to have failed.  Considering that both of the remaining series have long-lived correlations, but weak partial correlations, it might be better to take a difference.  That will amplify the noise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test statistic -8.17261024485\n",
      "p-value 8.54236198904e-13\n",
      "#Lags 32\n",
      "Num observed 8751\n",
      "Critical Values {'1%': -3.4310974824840628, '5%': -2.8618703376017911, '10%': -2.5669458337323605}\n"
     ]
    }
   ],
   "source": [
    "ad_results=adfuller(t_detrend,autolag='BIC')\n",
    "names=[\"Test statistic\",\"p-value\",\"#Lags\",\"Num observed\",\"Critical Values\"]\n",
    "\n",
    "for i in range(0,5):\n",
    "    print( names[i],ad_results[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "?pd.date_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Goals\n",
    "\n",
    "What is my goal here?  To develop a model for day-ahead electricity forecasts, that optimizes the mean square error.  I have been playing with trying to capture an entire year's data.  (I wanted to explore the seasonal patterns, and try fitting a basic model.)\n",
    "\n",
    "However, trying to forecast a year's power (at daily resolution) is a fool's errand.  What is a smaller task, I can play with?\n",
    "I could try fitting day-ahead curves, using the last week's data.  Each day is then its own problem, with much more manageable requirements.\n",
    "To finish the ARMA stuff, I can estimate the expected ARMA parameters from a bunch of separate two-week periods. Once the model parameters\n",
    "are set, I can fit the model for each period, and forecast the next day's behaviour. Those parameters can the nbe used in the future, perhaps\n",
    "with feedback based on how they worked in the past.\n",
    "\n",
    "I also want to fit a Long Short-Term Memory neural network to this data.  This will be done in TensorFlow,  where I will try to build the network using the lower-level instructions, rather than any built-in operations .  This problem seems a good match for this technique, since there are clear correlations, and some scope for nonlinearities.  In this case we must select parameters for the size and depth of\n",
    "the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Appendices\n",
    "\n",
    "I've accumulated things I was playing with here, such as the distinction between auto-correlation, and partial auto-correlation plots, and numpy's fft syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## ACF vs PACF\n",
    "\n",
    "The following example helped me understand the distinction between the ACF and PACF.  The PACF tries to remove the correlation due to the intermediate variables, to find how the innovation/noise a step $k$ in the past, affects the present.   The following model models a random walk, and adds on a delayed copy of itself.  You can see the peaks in the PACF at lags corresponding to the enforced lag.  So the ACF tells us the order of the auto-regression, and PACF tells us the order of the moving average.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb99c70358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Nx=10000\n",
    "s=2\n",
    "x = np.arange(0,Nx)\n",
    "z= np.random.randn(Nx)\n",
    "z1=np.zeros(Nx)\n",
    "\n",
    "z1[s:Nx] = z[0:Nx-s]\n",
    "y = 2*x +2*z - .5*z1\n",
    "\n",
    "tindex = pd.date_range('2015-01-01',periods=Nx)\n",
    "ts = pd.Series(y,index=tindex)\n",
    "plt.figure()\n",
    "plot_acf(ts,'r-+','T0',nl=10)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "name": "EBA_explore.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
