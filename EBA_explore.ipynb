{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from get_weather_data import convert_isd_to_df, convert_state_isd\n",
    "\n",
    "pi=np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with Mahlon Sweet Field\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with Salem Municipal Airport/McNary Field\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with Portland International Airport\n"
     ]
    }
   ],
   "source": [
    "air_df = pd.read_csv('data/air_code_df.gz')\n",
    "\n",
    "#Just get the weather station data for cities in Oregon.\n",
    "df_weather=convert_state_isd(air_df,'OR')\n",
    "\n",
    "#Read all of the weather data in.\n",
    "#df_weather=pd.read_csv('data/airport_weather.gz',index_col=0,parse_dates=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#load electricity data\n",
    "df_eba=pd.read_csv('data/EBA_time.gz',index_col=0,parse_dates=True)\n",
    "df_region_eba=pd.read_csv('data/EBA_region_time.gz',index_col=0,parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Select temperature for Portland, OR\n",
    "msk1=np.array(df_weather['city']=='Portland')\n",
    "msk2=np.array(df_weather['state']=='OR')\n",
    "\n",
    "df_pdx_weath=df_weather.loc[msk1&msk2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#get electricity data for Portland General Electric\n",
    "msk=df_eba.columns.str.contains('Portland')\n",
    "df_pdx=df_eba.loc[:,msk]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Anomaly Detection\n",
    "\n",
    "A quick look at the portland data suggests that there are both real outliers, and ones from errors in the data process (100x surrounding values).  \n",
    "\n",
    "Tests should be for total interchange = 0, and \n",
    "Demand=Net Gen - Net Interchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbc24a8668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7efbc2340b70>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnew=[735567.85,736564,0,10000]\n",
    "fig=plt.figure(figsize=(15,6))\n",
    "ax = fig.add_axes([0.1, 0.1, 0.6, 0.75])\n",
    "ax.plot(df_pdx)\n",
    "ax.legend(df_pdx.columns.values,loc='upper left',bbox_to_anchor=(1,1),prop={'size':9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Check that the energy is balanced for this small subset: Demand = Net Generation - Net Interchange.\n",
    "#Seems to not be true.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efba1317400>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb9f648a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dem=df_pdx.iloc[:,0]\n",
    "gen=df_pdx.iloc[:,2]\n",
    "net=df_pdx.iloc[:,3]\n",
    "plt.figure()\n",
    "plt.plot(dem-(-gen+net),'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The data in later 2015 seem pretty crappy.  Looking at the EBA user notes, this seems to be a common complaint.\n",
    "The other errors seem to involve some anomalous zero points in the temperature series.  For temperature series where huge swings are unlikely\n",
    "it may be feasible to replace anomalous 0 values with the average of the neighbouring points.  In case of actual zero values, this shouldn't be a large problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Make a combined Portland Dataframe for demand vs weather.\n",
    "dem=df_pdx.iloc[:,0]\n",
    "df_joint=pd.DataFrame(dem)\n",
    "df_joint=df_joint.join(df_pdx_weath)\n",
    "df_joint.head()\n",
    "#plt.figure()\n",
    "x=df_joint.iloc[:,0]\n",
    "y=df_joint.iloc[:,1]\n",
    "df_joint['TempShift']=150+abs(df_joint['Temp']-150)\n",
    "df_joint=df_joint.rename(columns={df_joint.columns[0]:'Demand'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     Demand  CloudCover  DewTemp  Precip-1hr  Precip-6hr  \\\n2015-07-01 00:00:00  3648.0         2.0    144.0         0.0         NaN   \n2015-07-01 01:00:00  3658.0         0.0    150.0         0.0         NaN   \n2015-07-01 02:00:00  3608.0         0.0    156.0         0.0         NaN   \n2015-07-01 03:00:00  3493.0         0.0    156.0         0.0         NaN   \n2015-07-01 04:00:00  3374.0         0.0    150.0         0.0         NaN   \n\n                     Pressure   Temp  WindDir  WindSpeed      city  \\\n2015-07-01 00:00:00   10150.0  333.0    310.0       77.0  Portland   \n2015-07-01 01:00:00   10146.0  322.0    310.0       93.0  Portland   \n2015-07-01 02:00:00   10145.0  317.0    310.0       82.0  Portland   \n2015-07-01 03:00:00   10146.0  300.0    320.0       62.0  Portland   \n2015-07-01 04:00:00   10148.0  278.0    320.0       51.0  Portland   \n\n                      city, state     region state  TempShift  \n2015-07-01 00:00:00  Portland, OR  Northwest    OR      333.0  \n2015-07-01 01:00:00  Portland, OR  Northwest    OR      322.0  \n2015-07-01 02:00:00  Portland, OR  Northwest    OR      317.0  \n2015-07-01 03:00:00  Portland, OR  Northwest    OR      300.0  \n2015-07-01 04:00:00  Portland, OR  Northwest    OR      278.0  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_joint.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbb9a4b518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Energy Usage vs Temperature in Portland, OR')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(df_joint['Temp'],df_joint.iloc[:,0],'rx')\n",
    "plt.ylabel('Hourly Demand (kWh)')\n",
    "plt.xlabel('Temperature (Celcius x10)')\n",
    "plt.title('Energy Usage vs Temperature in Portland, OR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbb9752ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Energy Usage vs Temperature in Portland, OR')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(df_joint['WindSpeed'],df_joint.iloc[:,0],'rx')\n",
    "plt.xlabel('Wind Speed (m/s x10)')\n",
    "plt.ylabel('Hourly Demand (kWh)')\n",
    "plt.title('Energy Usage vs Temperature in Portland, OR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbb98c6f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Energy Usage vs Precipitation in Portland, OR')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(df_joint['Precip-1hr'],df_joint.iloc[:,0],'rx')\n",
    "plt.ylabel('Demand (kWh)')\n",
    "plt.xlabel('Precipitation (mm x 10)')\n",
    "plt.title('Energy Usage vs Precipitation in Portland, OR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So the scatterplot for temperature versus demand shows a clear (expected) trend as the tempererature becomes excessively hot or cold.\n",
    "It looks like two blobs with similar slopes for deviations from 15 Celcius.  You can also see anomalous values at zero,\n",
    "and extremely high values.  I'm skeptical of the 9000kWh value?\n",
    "\n",
    "Let's also plot the correlation matrix across the whole time series.  Evidently a temperature  deviation from 15 celcius shows the largest correlation, with wind speed being the next most important.\n",
    "I know the coldest temperatures in some places emerge in inversions (with absolutely no air movement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "My naive model for how energy usage would vary is a factor for deviation from some ideal temperature, as well as daily and yearly oscillations.\n",
    "\\begin{equation}\n",
    "    \\text{Demand}= A_0+A|T-T_0|\\sin\\left( \\frac{2\\pi t}{24}+\\phi_{\\text{day}}\\right)\\sin\\left(\\frac{2\\pi d}{365}+\\phi_{\\text{year}}\\right)\n",
    "\\end{equation}\n",
    "where $t$ is the hour of the day in 24 hour time, and $d$ is the number of days since the start of the year.\n",
    "\n",
    "To get a sense of those oscillations, let's look at the autocorrelation function for demand, as a function of time.  (Alternatively, the power spectrum?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Removing Extremes\n",
    "\n",
    "Lets try to clean up some of this data.\n",
    "My strategy is to find missing (or zero values) or excessive data.  Find values larger than 3x standard deviations from the mean.\n",
    "Those extreme values are replaced with the mean of the two neighbouring points.\n",
    "This is also carried out for points with zero. Under the assumption that the data are otherwise continuous, the smoothing should not be a large distortion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def avg_extremes(df,window=2):\n",
    "    \"\"\"avg_extremes(df)\n",
    "    Replace extreme outliers, or zero values with the average on either side.\n",
    "    Suitable for occasional anomalous readings.\n",
    "    \"\"\"\n",
    "    mu=df.mean()\n",
    "    sd=df.std()\n",
    "    msk1=(df-mu)>4*sd\n",
    "    msk2 = df==0\n",
    "    msk=msk1|msk2\n",
    "    print( \"Number of extreme values {}. Number of zero values {}\".format(sum(msk1),sum(msk2)))\n",
    "    ind= np.arange(len(df))[msk]\n",
    "    for i in ind:\n",
    "        df.iloc[i]=(df.iloc[i-window]+df.iloc[i-window])/2\n",
    "\n",
    "    return df\n",
    "\n",
    "def remove_na(df,window=2):\n",
    "    \"\"\"remove_na(df)\n",
    "    Replace all NA values with the mean value of the series.\n",
    "    \"\"\"\n",
    "    na_msk=np.isnan(df.values)\n",
    "    #first pass:replace them all with the mean value - if a whole day is missing.\n",
    "    df[na_msk]=df.mean()\n",
    "\n",
    "    ind= np.arange(len(df))[na_msk]\n",
    "    #for isolated values, replace by the average on either side.    \n",
    "    for i in ind:\n",
    "        df.iloc[i]=(df.iloc[i-window]+df.iloc[i-window])/2\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Auto regressive modelling\n",
    "\n",
    "A popular approach assumes that the current demand is probably the same as the previous demand, with some noise.\n",
    "This is the auto-regressive, integrated, moving average (ARIMA) class of models that are popular linear models within econometric forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(JBM) Freq is  24\n",
      "(JBM) Freq is  24\n"
     ]
    }
   ],
   "source": [
    "    #Carry out the \"demand\" and \"temperature\" seasonal decompositions.\n",
    "    dem_decomposition = seasonal_decompose(dem,two_sided=False)\n",
    "    dem_mu=dem.mean()\n",
    "    dem_trend = dem_decomposition.trend/dem_mu  #Find rolling average over most important period.\n",
    "    dem_seasonal = dem_decomposition.seasonal/dem_mu  #Find the dominant frequency components\n",
    "    dem_residual = dem_decomposition.resid/dem_mu  #Whatever is left.\n",
    "\n",
    "    temp_decomposition = seasonal_decompose(temp,two_sided=False)\n",
    "    temp_mu=temp.mean()\n",
    "    temp_trend = temp_decomposition.trend/temp_mu  #Find rolling average over most important period.\n",
    "    temp_seasonal = temp_decomposition.seasonal/temp_mu  #Find the dominant frequency components\n",
    "    temp_residual = temp_decomposition.resid/temp_mu  #Whatever is left.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def make_seasonal_plots(dem,temp,per,nlags):\n",
    "    \"\"\"Make seasonal decomposition of temperature, and demand curves.\n",
    "    Plots those decompositions, and their correlation/autocorrelation plots.\n",
    "    dem- input demand series\n",
    "    temp-input temperature series\n",
    "    per - input date to index on for plotting, e.g. '2016-03'\n",
    "    nlags - number of lags for correlation plots.\n",
    "    \"\"\"\n",
    "    #Carry out the \"demand\" and \"temperature\" seasonal decompositions.\n",
    "    dem_decomposition = seasonal_decompose(dem,two_sided=False)\n",
    "    dem_mu=dem.mean()\n",
    "    dem_trend = dem_decomposition.trend/dem_mu  #Find rolling average over most important period.\n",
    "    dem_seasonal = dem_decomposition.seasonal/dem_mu  #Find the dominant frequency components\n",
    "    dem_residual = dem_decomposition.resid/dem_mu  #Whatever is left.\n",
    "\n",
    "    temp_decomposition = seasonal_decompose(temp,two_sided=False)\n",
    "    temp_mu=temp.mean()\n",
    "    temp_trend = temp_decomposition.trend/temp_mu  #Find rolling average over most important period.\n",
    "    temp_seasonal = temp_decomposition.seasonal/temp_mu  #Find the dominant frequency components\n",
    "    temp_residual = temp_decomposition.resid/temp_mu  #Whatever is left.\n",
    "\n",
    "    #Plot out the decompositions\n",
    "    plt.figure(figsize=(15,9))\n",
    "    plt.title('Normalized Seasonal Decomposition')\n",
    "    plt.subplot(411)\n",
    "    plt.plot(dem_trend[per],'b',temp_trend[per],'k')\n",
    "    plt.ylabel('Trend')\n",
    "    plt.subplot(412)\n",
    "    plt.plot(dem_seasonal[per],'b',temp_seasonal[per],'k')\n",
    "    plt.ylabel('Seasonal Oscillation')\n",
    "    plt.subplot(413)\n",
    "    plt.plot(dem_residual[per],'b',temp_residual[per],'k')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.subplot(414)\n",
    "    plt.plot(dem[per]/dem_mu,'b',temp[per]/temp_mu,'k')\n",
    "    plt.ylabel('Data')\n",
    "    plt.show()\n",
    "\n",
    "    #Plot the auto-correlation plots.\n",
    "    nlags=np.min([len(dem[per])-1,nlags,len(temp[per])-1])\n",
    "    print('Nlags',nlags)\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plot_acf(temp_residual[per],'b-x','Temp Residual',nl=nlags)\n",
    "    plot_acf(dem_residual[per],'r-+','Demand Residual',nl=nlags)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plot_acf(temp[per],'b-x','Temp',nl=nlags)\n",
    "    plot_acf(dem[per],'r-+','Demand',nl=nlags)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return None\n",
    "\n",
    "def plot_acf(ts,ls,line_label,nl=50):\n",
    "    \"\"\"plot_acf(ts,ls,nl)\n",
    "    Plot the auto-correlation plots for a timeseries (ts) up to a given number of lags (nl)\n",
    "    Give a specific linestyle (ls), and label.\n",
    "    \"\"\"\n",
    "    #Actually do those auto-corellations, on the series, and its absolute value.\n",
    "    lag_acf = acf(ts,nlags=nl)\n",
    "    lag_pacf=pacf(ts,nlags=nl,method='ols')\n",
    "    #5% confidence intervals.\n",
    "    sd = 1.96/np.sqrt(len(ts))\n",
    "    #Make some purty subplots.\n",
    "    plt.subplot(121)\n",
    "    plt.ylabel('Auto Correlation')\n",
    "    plt.plot(lag_acf,ls,label=line_label)\n",
    "    plt.axhline(y=sd,color='gray')\n",
    "    plt.axhline(y=-sd,color='gray')\n",
    "    plt.ylabel('Auto Correlation')\n",
    "    plt.xlabel('Lag')\n",
    "    plt.subplot(122)\n",
    "    plt.ylabel('Partial Auto Correlation')\n",
    "    plt.xlabel('Lag')\n",
    "    plt.axhline(y=sd,color='gray')\n",
    "    plt.axhline(y=-sd,color='gray')\n",
    "    plt.plot(lag_pacf,ls,label=line_label)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb98a40cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb989024a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathan/anaconda3/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:106: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nlags 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb989dde10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extreme values 0. Number of zero values 148\n",
      "(JBM) Freq is  24\n",
      "(JBM) Freq is  24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extreme values 1. Number of zero values 3\n"
     ]
    }
   ],
   "source": [
    "dem=df_joint['Demand'].asfreq('H')\n",
    "dem=avg_extremes(dem)\n",
    "dem=remove_na(dem)\n",
    "\n",
    "temp=df_joint['Temp'].asfreq('H')\n",
    "temp=avg_extremes(temp)\n",
    "temp=remove_na(temp)\n",
    "\n",
    "make_seasonal_plots(dem,temp,'2016-03',50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Evidently, this finds the day timescale.  I'm a bit skeptical of these plots, and this approach (trying simple seasonality reduction on the whole data set at once).  I think the seasonal component has not been completely removed.\n",
    "The method works by estimating the frequency of the data.  The trend is found by taking averages across each period, and the seasonality is found by averages over multiple period.  The remainder once these are subtracted is the \"noise\" process.\n",
    "\n",
    "There is an additional year-long oscillations are still buried in the trend.  Of course, this data\n",
    "has only two years worth of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test statistic -1.28011239076\n",
      "p-value 0.638221098471\n",
      "#Lags 20\n",
      "Num observed 699\n",
      "Critical Values {'1%': -3.4397398095543279, '5%': -2.8656836898038098, '10%': -2.5689766074363334}\n"
     ]
    }
   ],
   "source": [
    "#Do some tests for stationarity\n",
    "ad_results=adfuller(dem['2016-11'],autolag='BIC')\n",
    "names=[\"Test statistic\",\"p-value\",\"#Lags\",\"Num observed\",\"Critical Values\"]\n",
    "\n",
    "for i in range(0,5):\n",
    "    print( names[i],ad_results[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The above plot is the raw auto-correlation between the demand and temperature.  I think there is a substantive daily oscillation left by the naive seasonal approach.  This assumes a single oscillation, repeated for all cases.  In this data however, there is a clear daily signal, which it picks out.  However, this will vary over the course of the year.\n",
    "\n",
    "Diebold's text \"Elements of Forecasting\" suggests putting in dummy variables for seasonality.  So hour of day, and day of year.  The resulting series.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extreme values 0. Number of zero values 2\n",
      "Number of extreme values 0. Number of zero values 8\n",
      "(JBM) Freq is  7\n",
      "(JBM) Freq is  7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb99b11208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nlags 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathan/anaconda3/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:106: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb99f8aeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb99b6bf28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Compare series at noon\n",
    "msk=df_joint.index.hour==9\n",
    "\n",
    "dem=df_joint[msk]['Demand'].asfreq('D')\n",
    "dem=avg_extremes(dem)\n",
    "dem=remove_na(dem)\n",
    "\n",
    "temp=df_joint[msk]['Temp'].asfreq('D')\n",
    "temp=avg_extremes(temp)\n",
    "temp=remove_na(temp)\n",
    "make_seasonal_plots(dem,temp,'2016',40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "So looking at just an hour of the day, the seasonal split manages to work fairly well at making the residual series a stationary one.\n",
    "The \"trend\" is effectively picking out the anticipated annual shifts, and the \"seasonality\" is pulling out a small week long oscillation (the amplitude is much smaller than the trend).  The residuals also seem to be stationary now.  \n",
    "\n",
    "The autocorrelation plots also show some oscillations (I think the seasonal reduction is pretty crap), but here they decay to within error after\n",
    "6 days.  \n",
    "The raw demand auto-correlations might be showing annual oscillations in temperature and electricity usage that would get stronger from 120-240 days.\n",
    "\n",
    "Turns out the \"seasonal\" part \n",
    "\n",
    "If we look at the correlation plots for various hours there are a couple clear trends.  Looking at 6pm, shows a really clear weekly (7 day) signal.  This is not as obvious at other times of day (6am, 9am, 12pm).  Note that I have not selected out weekends, or holidays here.  Weekends might be strongly contributing to the weekly oscillation.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Fourier Plots\n",
    "\n",
    "I'm curious about the power spectrum for this series.  I'm also unfamiliar with Python's FFT routine, so this is a good time to play around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extreme values 0. Number of zero values 0\n"
     ]
    }
   ],
   "source": [
    "#clean up the data\n",
    "dem_t=df_joint['Demand']['2015-07':'2016-06'].copy()\n",
    "dem_t=avg_extremes(dem_t)\n",
    "dem_t=remove_na(dem_t)\n",
    "dem_tv=dem_t.values\n",
    "\n",
    "#set up FFT time/frequency scales\n",
    "Nt = len(dem_tv)\n",
    "#scale time to days.\n",
    "Tmax = Nt/24\n",
    "dt = 1/24\n",
    "t = np.arange(0,Tmax,dt)\n",
    "df = 1/Tmax\n",
    "fmax=0.5/dt\n",
    "f = np.arange(-fmax,fmax,df)\n",
    "\n",
    "#carry out fft \n",
    "dem_f=np.fft.fftshift(dem_tv)\n",
    "dem_f=np.fft.fft(dem_f)\n",
    "dem_f=np.fft.ifftshift(dem_f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efba0485630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "spec=abs(dem_f)**2\n",
    "spec/=sum(spec)\n",
    "plt.semilogy(f,spec)\n",
    "fcut=1/7\n",
    "plt.axis([-10*fcut,10*fcut,1E-10,1])\n",
    "plt.xlabel('Frequency (1/day)')\n",
    "plt.ylabel('Normalized Demand Power Spectrum')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "This is a normalized power spectrum for the demand data.  You can clearly see the peaks arising from daily and weekly oscillations.\n",
    "There is a small peak at very low frequencies, which corresponds to the annual oscillation.  However, given we only have 2 years of data, this\n",
    "is almost exactly the Nyquist frequency (lowest frequency that can be resolved).  Let's examine both the high (intra-day) and low (year-long) frequency scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efba04b9be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "plt.subplot(211)\n",
    "plt.plot(f,spec)\n",
    "fcut=1/365\n",
    "plt.axis([-12*fcut,12*fcut,1E-10,0.05])\n",
    "plt.xlabel('Frequency (1/day)')\n",
    "plt.ylabel('Normalized Demand Power Spectrum')\n",
    "plt.title('Year long power')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(f,spec)\n",
    "fcut=5\n",
    "plt.xlabel('Frequency (1/day)')\n",
    "plt.ylabel('Normalized Demand Power Spectrum')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The top figure, shows the low frequency (year-long) data.  The lower plot shows nearly the whole frequency spectrum.  Note the peaks at 1,2,3,etc.  These are the daily frequency oscillations.  They also share correlations with other frequencies fo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def remove_peak(Y,f,center,width):\n",
    "    \"\"\"remove_yearly\n",
    "    Assumes there is a yearly trend.\n",
    "    Subtracts off everything on a monthly or longer timescale. (around 1/30)\n",
    "    Replaces that with the average of the neighbouring points.\n",
    "    \n",
    "    inputs:\n",
    "    Y - initial centered Fourier transform\n",
    "    f - list of frequencies Fourier transform is evaluated a\n",
    "    shape - function to use to define the window.  Takes a position input, and width. \n",
    "    center - frequency to center filter at, to remove        \n",
    "    width - width of the filter.\n",
    "\n",
    "    return:\n",
    "    detrended -transform after subtracting off this component.  \n",
    "    trend     -the subtracted portion.\n",
    "    \"\"\" \n",
    "    #find stuff within +/- 1 width\n",
    "    trend_msk= abs(f-center)<width\n",
    "    #find stuff within +/- 1.5 widths, and not inside 1 ith\n",
    "    mean_msk = abs(f-center)<1.5*width\n",
    "    mean_msk = mean_msk & ~trend_msk\n",
    "\n",
    "    replace_avg = Y[mean_msk].mean()\n",
    "    replace_std = Y[mean_msk].std()\n",
    "    trend=np.zeros(len(f))+0j\n",
    "    trend[trend_msk] = Y[trend_msk]-replace_avg\n",
    "    detrend = Y-trend\n",
    "    return trend, detrend\n",
    "\n",
    "f_trend,f_detrend=remove_peak(dem_f,f,0,4/365)\n",
    "\n",
    "f_trend_tot=f_trend\n",
    "\n",
    "#remove daily oscillations\n",
    "for k in range(1,3):\n",
    "    #positive peak\n",
    "    f_trend,f_detrend=remove_peak(f_detrend,f,k,4/365)\n",
    "    f_trend_tot+=f_trend\n",
    "    #negative peak\n",
    "    f_trend,f_detrend=remove_peak(f_detrend,f,-k,4/365)\n",
    "    f_trend_tot+=f_trend\n",
    "\n",
    "#remove weekly oscillations\n",
    "for i in range(1,6):\n",
    "    f0=i/7\n",
    "    f_trend,f_detrend=remove_peak(f_detrend,f,f0,4/365)\n",
    "    f_trend_tot+=f_trend\n",
    "    f_trend,f_detrend=remove_peak(f_detrend,f,-f0,4/365)\n",
    "    f_trend_tot+=f_trend\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb988528d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[-2, 2, 1000.0, 100000000.0]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lorentz(f,w):\n",
    "    l = w*w/(w*w + f*f)\n",
    "    return l\n",
    "\n",
    "def gauss(f,w):\n",
    "    g = np.exp(-f*f/(2*w*w))\n",
    "    return g\n",
    "plt.figure(figsize=(12,9))\n",
    "plt.semilogy(f,abs(f_trend_tot),f,abs(f_detrend))\n",
    "plt.axis([-2,2,1E3,1E8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#check out what this detrending looks like.\n",
    "#\n",
    "def invert_fft(Y):\n",
    "    #undo the fftshifts, invert fft, and take the real part\n",
    "    y=np.fft.fftshift(Y)\n",
    "    y=np.fft.ifft(y)\n",
    "    y=np.fft.fftshift(y)\n",
    "    y=np.real(y)\n",
    "    return y\n",
    "\n",
    "t_trend=invert_fft(f_trend_tot)\n",
    "t_detrend=invert_fft(f_detrend)\n",
    "\n",
    "# t_trend=pd.Series(t_trend,index=dem_t.index)\n",
    "# t_detrend=pd.Series(t_detrend,index=dem_t.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8784, 8784, 8784, 8784)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t_detrend),len(t_trend),len(dem_t),len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb98501940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efb9850aa58>,\n <matplotlib.lines.Line2D at 0x7efb9850ac18>,\n <matplotlib.lines.Line2D at 0x7efb984e4160>]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "plt.plot(t,dem_t,'b',t,t_trend,'r',t,t_detrend,'g')\n",
    "#plt.axis([550,560,min(t_detrend),max(dem_t)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So that used just July/2015-June/2016 data to find the trend.  Let's now see how this does when applied to the next year's data.\n",
    "The trend can be appended to itself.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_trend=np.array([t_trend,t_trend])\n",
    "len(t_trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efba01f2e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathan/anaconda3/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:106: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "plot_acf(np.diff(t_detrend),'r-x','Manually Detrended',nl=30)\n",
    "plot_acf(dem_residual['2016-01'],'b-x','Detrended',nl=30)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "So, that was a waste of time.  My manual detrend-everything-at-once approach seems to have failed.  Considering that both of the remaining series have long-lived correlations, but weak partial correlations, it might be better to take a difference.  That will amplify the noise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test statistic -12.9280558087\n",
      "p-value 3.7512304142e-24\n",
      "#Lags 44\n",
      "Num observed 17499\n",
      "Critical Values {'1%': -3.4307237504722679, '5%': -2.8617051832726124, '10%': -2.5668579227683557}\n"
     ]
    }
   ],
   "source": [
    "ad_results=adfuller(t_detrend,autolag='BIC')\n",
    "names=[\"Test statistic\",\"p-value\",\"#Lags\",\"Num observed\",\"Critical Values\"]\n",
    "\n",
    "for i in range(0,5):\n",
    "    print( names[i],ad_results[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb986ee6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "Nx=100\n",
    "x = np.arange(0,Nx)\n",
    "z= np.random.randn(Nx)\n",
    "z1=np.zeros(Nx)\n",
    "z1[1:100] = z[0:99]\n",
    "z1[0]=0\n",
    "y = 2*x +0.5*z + 0.5*z1\n",
    "\n",
    "tindex = pd.date_range('2015-01-01',periods=Nx)\n",
    "ts = pd.Series(y,index=tindex)\n",
    "plt.figure()\n",
    "plot_acf(ts,'r-+','T0',nl=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-229-c54d9c909cf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'append'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "?pd.date_range"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "name": "EBA_explore.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
