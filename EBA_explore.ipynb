{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from get_weather_data import convert_isd_to_df, convert_state_isd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with Mahlon Sweet Field\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with Salem Municipal Airport/McNary Field\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with Portland International Airport\n"
     ]
    }
   ],
   "source": [
    "air_df = pd.read_csv('data/air_code_df.gz')\n",
    "\n",
    "#Just get the weather station data for cities in Oregon.\n",
    "df_weather=convert_state_isd(air_df,'OR')\n",
    "\n",
    "\n",
    "#Read all of the weather data in.\n",
    "#df_weather=pd.read_csv('data/airport_weather.gz',index_col=0,parse_dates=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     CloudCover  DewTemp  Precip-1hr  Precip-6hr  Pressure  \\\n2017-10-18 01:00:00         NaN    122.0        99.0         NaN   10202.0   \n2017-10-18 02:00:00         NaN    122.0        99.0         NaN   10202.0   \n2017-10-18 03:00:00         NaN    122.0        99.0         NaN   10203.0   \n2017-10-18 04:00:00         NaN    122.0        99.0         NaN   10200.0   \n2017-10-18 05:00:00         NaN    122.0        99.0         NaN   10200.0   \n\n                      Temp  WindDir  WindSpeed    city city, state     region  \\\n2017-10-18 01:00:00  167.0    280.0       31.0  Eugene  Eugene, OR  Northwest   \n2017-10-18 02:00:00  156.0    350.0       31.0  Eugene  Eugene, OR  Northwest   \n2017-10-18 03:00:00  144.0    350.0       31.0  Eugene  Eugene, OR  Northwest   \n2017-10-18 04:00:00  144.0    360.0       21.0  Eugene  Eugene, OR  Northwest   \n2017-10-18 05:00:00  139.0      0.0        0.0  Eugene  Eugene, OR  Northwest   \n\n                    state  \n2017-10-18 01:00:00    OR  \n2017-10-18 02:00:00    OR  \n2017-10-18 03:00:00    OR  \n2017-10-18 04:00:00    OR  \n2017-10-18 05:00:00    OR  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_eba=pd.read_csv('data/EBA_time.gz',index_col=0,parse_dates=True)\n",
    "df_region_eba=pd.read_csv('data/EBA_region_time.gz',index_col=0,parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Select temperature for Portland, OR\n",
    "#Had bug in selecting airports - was assuming all Portlands are in ME, but just getting PDX.\n",
    "msk1=np.array(df_weather['city']=='Portland')\n",
    "msk2=np.array(df_weather['state']=='OR')\n",
    "\n",
    "df_pdx_weath=df_weather.loc[msk1&msk2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#get electricity data for Portland General Electric\n",
    "msk=df_eba.columns.str.contains('Portland')\n",
    "df_pdx=df_eba.loc[:,msk]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Anomaly Detection\n",
    "\n",
    "A quick look at the portland data suggests that there are both real outliers, and ones from errors in the data process (100x surrounding values).  \n",
    "\n",
    "Tests should be for total interchange = 0, and \n",
    "Demand=Net Gen - Net Interchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# def clean_df(df):\n",
    "#     \"\"\"clean_df(df)\n",
    "#     Replace extreme values with the value on either side. \n",
    "#     Detect extreme values when the finite difference exceeds the variance? \n",
    "#     But this coul\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbc24a8668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7efbc2340b70>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnew=[735567.85,736564,0,10000]\n",
    "fig=plt.figure(figsize=(15,6))\n",
    "ax = fig.add_axes([0.1, 0.1, 0.6, 0.75])\n",
    "ax.plot(df_pdx)\n",
    "ax.legend(df_pdx.columns.values,loc='upper left',bbox_to_anchor=(1,1),prop={'size':9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Check that the energy is balanced for this small subset: Demand = Net Generation - Net Interchange.\n",
    "#Seems to not be true.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efba1317400>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb9f648a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dem=df_pdx.iloc[:,0]\n",
    "gen=df_pdx.iloc[:,2]\n",
    "net=df_pdx.iloc[:,3]\n",
    "plt.figure()\n",
    "plt.plot(dem-(-gen+net),'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The data in later 2015 seem pretty crappy.  Looking at the EBA user notes, this seems to be a common complaint.\n",
    "The other errors seem to involve some anomalous zero points in the temperature series.  For temperature series where huge swings are unlikely\n",
    "it may be feasible to replace anomalous 0 values with the average of the neighbouring points.  In case of actual zero values, this shouldn't be a large problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Make a combined Portland Dataframe for demand vs weather.\n",
    "dem=df_pdx.iloc[:,0]\n",
    "df_joint=pd.DataFrame(dem)\n",
    "df_joint=df_joint.join(df_pdx_weath)\n",
    "df_joint.head()\n",
    "#plt.figure()\n",
    "x=df_joint.iloc[:,0]\n",
    "y=df_joint.iloc[:,1]\n",
    "df_joint['TempShift']=150+abs(df_joint['Temp']-150)\n",
    "df_joint=df_joint.rename(columns={df_joint.columns[0]:'Demand'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     Demand  CloudCover  DewTemp  Precip-1hr  Precip-6hr  \\\n2015-07-01 00:00:00  3648.0         2.0    144.0         0.0         NaN   \n2015-07-01 01:00:00  3658.0         0.0    150.0         0.0         NaN   \n2015-07-01 02:00:00  3608.0         0.0    156.0         0.0         NaN   \n2015-07-01 03:00:00  3493.0         0.0    156.0         0.0         NaN   \n2015-07-01 04:00:00  3374.0         0.0    150.0         0.0         NaN   \n\n                     Pressure   Temp  WindDir  WindSpeed      city  \\\n2015-07-01 00:00:00   10150.0  333.0    310.0       77.0  Portland   \n2015-07-01 01:00:00   10146.0  322.0    310.0       93.0  Portland   \n2015-07-01 02:00:00   10145.0  317.0    310.0       82.0  Portland   \n2015-07-01 03:00:00   10146.0  300.0    320.0       62.0  Portland   \n2015-07-01 04:00:00   10148.0  278.0    320.0       51.0  Portland   \n\n                      city, state     region state  TempShift  \n2015-07-01 00:00:00  Portland, OR  Northwest    OR      333.0  \n2015-07-01 01:00:00  Portland, OR  Northwest    OR      322.0  \n2015-07-01 02:00:00  Portland, OR  Northwest    OR      317.0  \n2015-07-01 03:00:00  Portland, OR  Northwest    OR      300.0  \n2015-07-01 04:00:00  Portland, OR  Northwest    OR      278.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_joint.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Energy Usage vs Temperature in Portland, OR')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbc1a6bc18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(df_joint.iloc[:,0],df_joint['Temp'],'rx')\n",
    "plt.xlabel('Hourly Demand (kWh)')\n",
    "plt.ylabel('Temperature (Celcius x10)')\n",
    "plt.title('Energy Usage vs Temperature in Portland, OR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Energy Usage vs Temperature in Portland, OR')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb9f0f9518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(df_joint.iloc[:,0],df_joint['WindSpeed'],'rx')\n",
    "plt.xlabel('Hourly Demand (kWh)')\n",
    "plt.ylabel('Wind Speed (m/s x10)')\n",
    "plt.title('Energy Usage vs Temperature in Portland, OR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Energy Usage vs Temperature in Portland, OR')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb9ef45438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(df_joint.iloc[:,0],df_joint['CloudCover'],'rx')\n",
    "plt.xlabel('Hourly Demand (kWh)')\n",
    "plt.ylabel('Wind Speed (m/s x10)')\n",
    "plt.title('Energy Usage vs Temperature in Portland, OR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So the scatterplot for temperature versus demand shows a clear (expected) trend as the tempererature becomes excessively hot or cold.\n",
    "It looks like two blobs with similar slopes for deviations from 15 Celcius.  You can also see anomalous values at zero,\n",
    "and extremely high values.  I'm skeptical of the 9000kWh value?\n",
    "\n",
    "Let's also plot the correlation matrix across the whole time series.  Evidently a temperature  deviation from 15 celcius shows the largest correlation, with wind speed being the next most important.\n",
    "I know the coldest temperatures in some places emerge in inversions (with absolutely no air movement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "My naive model for how energy usage would vary is a factor for deviation from some ideal temperature, as well as daily and yearly oscillations.\n",
    "\\begin{equation}\n",
    "    \\text{Demand}= A_0+A|T-T_0|\\sin\\left( \\frac{2\\pi t}{24}+\\phi_{\\text{day}}\\right)\\sin\\left(\\frac{2\\pi d}{365}+\\phi_{\\text{year}}\\right)\n",
    "\\end{equation}\n",
    "where $t$ is the hour of the day in 24 hour time, and $d$ is the number of days since the start of the year.\n",
    "\n",
    "To get a sense of those oscillations, let's look at the autocorrelation function for demand, as a function of time.  (Alternatively, the power spectrum?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Removing Extremes\n",
    "\n",
    "Lets try to clean up some of this data.\n",
    "My strategy is to find missing (or zero values) or excessive data.  Find values larger than 3x standard deviations from the mean.\n",
    "Those extreme values are replaced with the mean of the two neighbouring points.\n",
    "This is also carried out for points with zero. Under the assumption that the data are otherwise continuous, the smoothing should not be a large distortion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def avg_extremes(df,window=2):\n",
    "    \"\"\"avg_extremes(df)\n",
    "    Replace extreme outliers, or zero values with the average on either side.\n",
    "    Suitable for occasional anomalous readings.\n",
    "    \"\"\"\n",
    "    mu=df.mean()\n",
    "    sd=df.std()\n",
    "    msk1=(df-mu)>4*sd\n",
    "    msk2 = df==0\n",
    "    msk=msk1|msk2\n",
    "    print( \"Number of extreme values {}. Number of zero values {}\".format(sum(msk1),sum(msk2)))\n",
    "    ind= np.arange(len(df))[msk]\n",
    "    for i in ind:\n",
    "        df.iloc[i]=(df.iloc[i-window]+df.iloc[i-window])/window\n",
    "\n",
    "    return df\n",
    "\n",
    "def remove_na(df):\n",
    "    \"\"\"remove_na(df)\n",
    "    Replace all NA values with the mean value of the series.\n",
    "    \"\"\"\n",
    "    na_msk=np.isnan(df.values)\n",
    "    df[na_msk]=df.mean()\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Auto regressive modelling\n",
    "\n",
    "A popular approach assumes that the current demand is probably the same as the previous demand, with some noise.\n",
    "This is the auto-regressive, integrated, moving average (ARIMA) class of models that are popular linear models within econometric forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extreme values 7. Number of zero values 0\n",
      "Number of extreme values 0. Number of zero values 5\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "\n",
    "dem=df_joint['Demand'].asfreq('H')\n",
    "dem=avg_extremes(dem)\n",
    "dem=remove_na(dem)\n",
    "\n",
    "temp=df_joint['Temp'].asfreq('H')\n",
    "temp=avg_extremes(temp)\n",
    "temp=remove_na(temp)\n",
    "\n",
    "\n",
    "make_seasonal_plots(dem,temp,'2016-03'):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def make_seasonal_plots(dem,temp,per,nlags):\n",
    "    \"\"\"Make seasonal decomposition of temperature, and demand curves.\n",
    "    Plots those decompositions, and their correlation/autocorrelation plots.\n",
    "    dem- input demand series\n",
    "    temp-input temperature series\n",
    "    per - input date to index on for plotting, e.g. '2016-03'\n",
    "    nlags - number of lags for correlation plots.\n",
    "    \"\"\"\n",
    "    #Carry out the \"demand\" and \"temperature\" seasonal decompositions.\n",
    "    dem_decomposition = seasonal_decompose(dem,two_sided=False)\n",
    "    dem_mu=dem.mean()\n",
    "    dem_trend = dem_decomposition.trend/dem_mu  #Find rolling average over most important period.\n",
    "    dem_seasonal = dem_decomposition.seasonal/dem_mu  #Find the dominant frequency components\n",
    "    dem_residual = dem_decomposition.resid/dem_mu  #Whatever is left.\n",
    "\n",
    "    temp_decomposition = seasonal_decompose(temp,two_sided=False)\n",
    "    temp_mu=temp.mean()\n",
    "    temp_trend = temp_decomposition.trend/temp_mu  #Find rolling average over most important period.\n",
    "    temp_seasonal = temp_decomposition.seasonal/temp_mu  #Find the dominant frequency components\n",
    "    temp_residual = temp_decomposition.resid/temp_mu  #Whatever is left.\n",
    "\n",
    "    #Plot out the decompositions\n",
    "    plt.figure(figsize=(15,9))\n",
    "    plt.title('Normalized Seasonal Decomposition')\n",
    "    plt.subplot(411)\n",
    "    plt.plot(dem_trend[per],'b',temp_trend[per],'k')\n",
    "    plt.ylabel('Trend')\n",
    "    plt.subplot(412)\n",
    "    plt.plot(dem_seasonal[per],'b',temp_seasonal[per],'k')\n",
    "    plt.ylabel('Seasonal Oscillation')\n",
    "    plt.subplot(413)\n",
    "    plt.plot(dem_residual[per],'b',temp_residual[per],'k')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.subplot(414)\n",
    "    plt.plot(dem[per]/dem_mu,'b',temp[per]/temp_mu,'k')\n",
    "    plt.ylabel('Data')\n",
    "    plt.show()\n",
    "\n",
    "    #Plot the auto-correlation plots.\n",
    "    nlags=np.min([len(dem[per])-1,nlags,len(temp[per])-1])\n",
    "    print('Nlags',nlags)\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plot_acf(temp_residual[per],'b-x','Temp Residual',nl=nlags)\n",
    "    plot_acf(dem_residual[per],'r-+','Demand Residual',nl=nlags)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plot_acf(temp[per],'b-x','Temp',nl=nlags)\n",
    "    plot_acf(dem[per],'r-+','Demand',nl=nlags)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Evidently, this finds the day timescale.  However, any longer year long oscillations are still buried in the trend.  Of course, this data\n",
    "has only two years worth of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test statistic -2.59481776746\n",
      "p-value 0.094073066772\n",
      "#Lags 1\n",
      "Num observed 28\n",
      "Critical Values {'1%': -3.6889256286443146, '5%': -2.9719894897959187, '10%': -2.6252957653061224}\n"
     ]
    }
   ],
   "source": [
    "#Do some tests for stationarity\n",
    "ad_results=adfuller(dem['2016-11'],autolag='BIC')\n",
    "names=[\"Test statistic\",\"p-value\",\"#Lags\",\"Num observed\",\"Critical Values\"]\n",
    "for i in range(0,5):\n",
    "    print( names[i],ad_results[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb9d0887f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb9dd494a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathan/anaconda3/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:106: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def plot_acf(ts,ls,line_label,nl=50):\n",
    "    \"\"\"plot_acf(ts,ls,nl)\n",
    "    Plot the auto-correlation plots for a timeseries (ts) up to a given number of lags (nl)\n",
    "    Give a specific linestyle (ls), and label.\n",
    "    \"\"\"\n",
    "    #Actually do those auto-corellations, on the series, and its absolute value.\n",
    "    lag_acf=acf(ts,nlags=nl)\n",
    "    lag_pacf=pacf(ts,nlags=nl,method='ols')\n",
    "    #5% confidence intervals.\n",
    "    sd = 1.96/np.sqrt(len(ts))\n",
    "    #Make some purty subplots.\n",
    "    plt.subplot(121)\n",
    "    plt.ylabel('Auto Correlation')\n",
    "    plt.plot(lag_acf,ls,label=line_label)\n",
    "    plt.axhline(y=sd,color='gray')\n",
    "    plt.axhline(y=-sd,color='gray')\n",
    "    plt.ylabel('Auto Correlation')\n",
    "    plt.xlabel('Lag')\n",
    "    plt.subplot(122)\n",
    "    plt.ylabel('Partial Auto Correlation')\n",
    "    plt.xlabel('Lag')\n",
    "    plt.axhline(y=sd,color='gray')\n",
    "    plt.axhline(y=-sd,color='gray')\n",
    "    plt.plot(lag_acf,ls,label=line_label)\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "?plt.plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The above plot is the raw auto-correlation between the demand and temperature.  I think there is a substantive daily oscillation left by the naive seasonal approach.  This assumes a single oscillation, repeated for all cases.  In this data however, there is a clear daily signal, which it picks out.  However, this will vary over the course of the year.\n",
    "\n",
    "Diebold's text \"Elements of Forecasting\" suggests putting in dummy variables for seasonality.  So hour of day, and day of year.  The resulting series.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb9ca27ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb9cc8b160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathan/anaconda3/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:106: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nlags 40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb9cbe2048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extreme values 0. Number of zero values 2\n",
      "Number of extreme values 0. Number of zero values 8\n"
     ]
    }
   ],
   "source": [
    "#Compare series at noon\n",
    "msk=df_joint.index.hour==9\n",
    "\n",
    "dem=df_joint[msk]['Demand'].asfreq('D')\n",
    "dem=avg_extremes(dem)\n",
    "dem=remove_na(dem)\n",
    "\n",
    "temp=df_joint[msk]['Temp'].asfreq('D')\n",
    "temp=avg_extremes(temp)\n",
    "temp=remove_na(temp)\n",
    "make_seasonal_plots(dem,temp,'2016',40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "So looking at just an hour of the day, the seasonal split manages to work fairly well at making the residual series a stationary one.\n",
    "The \"trend\" is effectively picking out the annual shifts, and the \"seasonality\" is pulling out a small week long oscillation (the amplitude is much smaller than the trend).  The residuals also seem to be stationary now.  I think the 20 day oscillation also comes out of the raw demand series.\n",
    "\n",
    "The raw demand series also might be showing annual oscillations in temperature and electricity usage that would get stronger from 120-240 days.\n",
    "\n",
    "Looking at 6pm, shows a really clear weekly (7 day) signal.  This is not as obvious at other times of day (6am, 9am, 12pm).  Note that I have\n",
    "not selected out weekends, or holidays here.  Weekends might be strongly contributing to the weekly oscillation.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Fourier Plots\n",
    "\n",
    "I'm curious about the power spectrum for this series.  I'm also unfamiliar with Python's FFT routine, so this is a good time to play around."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "name": "EBA_explore.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
