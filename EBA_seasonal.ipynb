{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Seasonal Regression\n",
    "\n",
    "The electricity demand series shows daily, weekly, and annual oscillations.  At a short time scale, I aim to capture the first two of these.\n",
    "\n",
    "The approaches I've seen suggest Fourier Series, linear regression, and Seasonal ARIMA.\n",
    "(I got quite stuck on how to detrend the series in a global fashion.)\n",
    "I will focus on building models on the last two weeks of data, with the goal of predicting electricity demand based on temperature, time of day, and day of week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Hyndman's Multiple Seasonal Exponential Smoothing\n",
    "\n",
    "This follows Rob Hyndman's approach towards multi-seasonal exponential smoothing.  (This generalizes the apparently well-known Holt-Winters smoothing).\n",
    "His analysis includes forecasts of electricity generation, based on utility data (from well over 10 years ago).\n",
    "\n",
    "I chose to follow this model since initial attempts at ARIMA rely on removing the seasonality, and I had hoped to just follow best practice with existing libraries.  Initial naive methods gave complete crap, and failed to remove the seasonal pattern, or even worse imposed one.  An initial attempt at Fourier filtering on over a year of data also left a \n",
    "\n",
    "Hyndman also seems to be a known author within the field of econometric time-series forecasting.  \n",
    "\n",
    "The original model for a variable $y_t$, with seasonal pattern with period $m$ is\n",
    "\\begin{align}\n",
    "  y_t &= l_{t-1}+b_{t-1} +s_{t-m} +\\epsilon_t\\\\\n",
    "  l_t &= l_{t-1} + \\alpha\\epsilon_t\\\\\n",
    "  b_t &= b_{t-1} + \\beta\\epsilon_t\\\\\n",
    "  s_{t} = s_{t-m} + \\gamma \\epsilon_t\n",
    "\\end{align}\n",
    "where $l_t$, b_t,s_t$ are the level, trend and seasonal patterns respectively.\n",
    "The noise is Gaussian and obeys\n",
    "$E[\\epsilon_t]=0, E[\\epsilon_t\\epsilon_s]=\\delta_{ts}\\sigma^2$, and $\\alpha,\\beta,\\gamma$ are constants between zero and one.  (He notes that $m+2$ estimates must be made for the initial values of the level, trend and seasonal pattern).\n",
    "\n",
    "Hyndman's model allows multiple seasons, and allows the sub-seasonal terms to be updated more quickly than once per large season.  In utility data, the short season is the daily oscillation, while the longer season comes from the weekly oscillation induced by the work week.  For hourly data, the daily cycle has length $m_1=24$, with the weekly cycle taking $m_2=168$.  The ratio between them is $k=m_2/m_1=7.$  The number of seasonal patterns is $r\\le k$.  \n",
    "\n",
    "(I'm going to change Hyndman's notation to use $\\mathbf{I}$ to denote indicator/step functions).\n",
    "\\begin{align}\n",
    "  y_t &= l_{t-1}+b_{t-1} +\\sum_{i=1}^r \\mathbf{I}_{t,i}s_{i,t-m_1} +\\epsilon_t\\\\\n",
    "  s_{i,t} = s_{i,t-m_1} + \\sum_{j=1}^r\\left(\\gamma_{ij}\\mathbf{I}_{t,j}\\right) \\epsilon_t  (i=1,2,\\ldots,r)\n",
    "  l_t &= l_{t-1} + b_{t-1}+\\alpha\\epsilon_t\\\\\n",
    "  b_t &= b_{t-1} + \\beta\\epsilon_t\\\\\n",
    "\\end{align}\n",
    "Here the indicator functions $\\mathbf{I}_{t,i}$ are unity if $t$ is in the seasonal pattern $i$, and zero otherwise.  For utility data, this will probably be weekday and holiday/weekend.  Here $\\gamma_{ij}$ denotes how much one seasonal pattern is updated based on another---Hyndman proposes a number of restrictions on these parameters.\n",
    "\n",
    "I will extend this to include an external variables for the deviation above a given temperature, so that $y_t\\rightarrow y_t+\\tau_p\\Theta(T_t-T_p)+\\tau_{n}\\Theta(T_n-T_t)$.\n",
    "\n",
    "He suggests using the first four weeks of data to estimate the parameters, by minimizing the squared error of the one-step ahead forecast.  Apparently maximum likelihood estimation was not recommended (10 years ago).\n",
    "\n",
    "So how to fit the parameters?  A really simple approach would be gradient descent?  Intuitively, the level is the average value, the bias is the average gradient.  The seasonality is the average seasonal pattern.  (This is the dumb STL decomposition used earlier?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from get_weather_data import convert_isd_to_df, convert_state_isd\n",
    "from EBA_util import remove_na, avg_extremes\n",
    "\n",
    "from numpy import pi,e\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in PDX Frame from file\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_joint=pd.read_csv('data/pdx_joint.txt',\n",
    "        index_col=0, parse_dates=True)\n",
    "    print('Read in PDX Frame from file')\n",
    "    dem=df_joint['Demand'].copy()\n",
    "    temp=df_joint['Temp'].copy()\n",
    "    fore=df_joint['Forecast'].copy()\n",
    "except:\n",
    "    air_df = pd.read_csv('data/air_code_df.gz')\n",
    "    #Just get the weather station data for cities in Oregon.\n",
    "    df_weather=convert_state_isd(air_df,'OR')\n",
    "    #Select temperature for Portland, OR\n",
    "    msk1=np.array(df_weather['city']=='Portland')\n",
    "    msk2=np.array(df_weather['state']=='OR')\n",
    "    df_pdx_weath=df_weather.loc[msk1&msk2]\n",
    "    #get electricity data for Portland General Electric\n",
    "    df_eba=pd.read_csv('data/EBA_time.gz',index_col=0,parse_dates=True)\n",
    "    msk=df_eba.columns.str.contains('Portland')\n",
    "    df_pdx=df_eba.loc[:,msk]\n",
    "    msk1=  df_pdx.columns.str.contains('[Dd]emand') \n",
    "    dem=df_pdx.loc[:,msk1]\n",
    "    #Make a combined Portland Dataframe for demand vs weather.\n",
    "    df_joint=pd.DataFrame(dem)\n",
    "    df_joint=df_joint.join(df_pdx_weath)\n",
    "    temp=df_joint['Temp']\n",
    "    df_joint['TempShift']=150+abs(temp-150)\n",
    "    df_joint = df_joint.rename(columns={df_joint.columns[0]:'Demand',\n",
    "             df_joint.columns[1]:'Forecast'})\n",
    "    df_joint.to_csv('data/pdx_joint.txt')\n",
    "\n",
    "    # msk=  df_eba.columns.str.contains('Demand') \\\n",
    "    #     & df_eba.columns.str.contains('demand')\n",
    "    # dem=df_pdx.loc[:,msk]\n",
    "    # #Make a combined Portland Dataframe for demand vs weather.\n",
    "    # df_joint=pd.DataFrame(dem)\n",
    "    # df_joint=df_joint.join(df_pdx_weath)\n",
    "    # temp=df_joint['Temp']\n",
    "    # df_joint['TempShift']=150+abs(temp-150)\n",
    "    # df_joint=df_joint.rename(columns={df_joint.columns[0]:'Demand',df_joint.columns[1]:'Forecast'})\n",
    "    # df_joint.to_csv('data/pdx_joint.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extreme values 0. Number of zero values 148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NA values 56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extreme values 1. Number of zero values 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NA values 156\n"
     ]
    }
   ],
   "source": [
    "#clean up data, remove NA\n",
    "dem = remove_na(dem)\n",
    "dem = avg_extremes(dem)\n",
    "temp = avg_extremes(remove_na(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'a' in ['a','b']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#from EBA_seasonal import multiseasonal as ms\n",
    "#Class for Multiseasonal model.\n",
    "class ms:\n",
    "    def __init__(self, l=0,b=0,s=np.zeros((2,24)),  alpha=0.1,beta=0.1,gamma=0.1*np.ones((2,2))):\n",
    "        self.l=l\n",
    "        self.b=b\n",
    "        self.s=s\n",
    "        self.alpha=alpha\n",
    "        self.beta=beta\n",
    "        #easiest to initialize via a single matrix.\n",
    "        self.g00 = gamma[0,0]\n",
    "        self.g01 = gamma[0,1]\n",
    "        self.g10 = gamma[1,0]\n",
    "        self.g11 = gamma[1,1]\n",
    "\n",
    "    def gamma(self):\n",
    "        gamma=np.array([[self.g00,self.g01],[self.g10,self.g11]])\n",
    "        return gamma\n",
    "\n",
    "\n",
    "    def fit_init_params(self,y,ninit=4*24*7):\n",
    "         \"\"\"fit_init_params(y)\n",
    "         Fits initial parameters for Hyndman's multi-seasonal model to\n",
    "         hourly electricity data.\n",
    "         (My guess on how to do this, similar to naive STL method used in \n",
    "         statstools.timeseries)\n",
    "         Finds level, bias and seasonal patterns based on first 4 weeks of data.  \n",
    "         \"\"\"\n",
    "         ysub = y[0:ninit]\n",
    "         yval = ysub.values\n",
    "         ##average value\n",
    "         self.l = np.mean(yval)\n",
    "         ##average shift\n",
    "         self.b = (yval[ninit-1]-yval[0])/ninit\n",
    "         ##remove mean pattern, subtract off level, and linear trend.\n",
    "         ysub = ysub-self.l-self.b*np.arange(ninit)\n",
    "         #mean seasonal pattern.\n",
    "         #second seasonal pattern is for weekends, with days\n",
    "         #Saturday/Sunday have dayofweek equal to 5 and 6.\n",
    "         #make a mask to select out weekends.\n",
    "         s2 = ysub.index.dayofweek >=5\n",
    "         #select out weekends, and regular days. \n",
    "         y_end = ysub[s2]\n",
    "         y_week= ysub[~s2]\n",
    "         n1 = int(len(y_week)/24)\n",
    "         n2 = int(len(y_end)/24)\n",
    "         self.s = np.zeros((2,24))\n",
    "         for n in range(n1):\n",
    "              self.s[0,:] = self.s[0,:]+y_week[n*24:(n+1)*24]/n1\n",
    "         for n in range(n2):\n",
    "              self.s[1,:] = self.s[1,:]+y_end[n*24:(n+1)*24]/n2\n",
    "\n",
    "    def predict_correct_onestep(self,yhat,ypred,t):\n",
    "         \"\"\"predict_correct_onestep\n",
    "         Updates time parameters based on differences between predicted \n",
    "         and measured.  Also predicts next step based on current values. \n",
    "         (Not fixing the model parameters for update strength!)\n",
    "         Work in Progress\n",
    "         \"\"\"\n",
    "         eps=(yhat-ypred)\n",
    "         #find seasonal patterns.  \n",
    "         m1 = t.hour                     \n",
    "         mr  = int(t.dayofweek>=5)\n",
    "         nmr = int(t.dayofweek<5)         \n",
    "         #Original version with bias in there too?\n",
    "         self.l = self.l + self.b + self.alpha*eps\n",
    "         self.b = self.b + self.beta*eps\n",
    "        \n",
    "         #ynew = self.l + self.s[mr,m1]         \n",
    "         # self.l = self.l +self.alpha*eps         \n",
    "         # self.b = self.b + self.beta*eps\n",
    "         # ynew = self.l  + self.s[mr,m1]\n",
    "         \n",
    "         #update row, and hour\n",
    "         ds = np.dot(self.gamma(),np.array([nmr,mr]))*eps\n",
    "         self.s[:,m1] = self.s[:,m1]+ds\n",
    "\n",
    "         #predict the next value given the updated parameters\n",
    "         ynew = self.l + self.s[mr,m1]\n",
    "         return ynew\n",
    "\n",
    "    def STL_onestep(self,y,ninit=4*24*7):\n",
    "         \"\"\"STL_onestep\n",
    "         Generates initial parameters, and then predicts remainder\n",
    "         of series for input data y.  \n",
    "         \"\"\"\n",
    "         self.fit_init_params(y,ninit=ninit)\n",
    "         ypred = np.zeros(len(y))         \n",
    "         t0=y.index[0]\n",
    "         m1 = t0.dayofweek>=5\n",
    "         m2 = t0.hour\n",
    "         \n",
    "         ti = y[:ninit].index\n",
    "         msk=ti.dayofweek>=5\n",
    "         ypred[:ninit] = self.l+self.b*np.arange(ninit) \\\n",
    "                  + self.s[msk.astype(int),ti.hour.values]\n",
    "\n",
    "         for i in range(ninit,len(y)):\n",
    "             ynew=self.predict_correct_onestep(y[i],\n",
    "                     ypred[i-1],y.index[i])\n",
    "             ypred[i] = ynew\n",
    "         # if i%(24*7) ==0:\n",
    "         #         print(\"l: {} b: {}\\n\".format(str(l),str(b)))\n",
    "         #         print(s,\"\\n\")\n",
    "         ypred=pd.Series(ypred,index=y.index)         \n",
    "         return ypred\n",
    "\n",
    "    def predict_correct_dayahead(self,y):\n",
    "         \"\"\"predict_correct_dayahead\n",
    "         Predict day-ahead demand given previous parameters.\n",
    "         Then update parameters given true demand.\n",
    "         \"\"\"\n",
    "         t0=y.index\n",
    "         m1 = t0.dayofweek>=5\n",
    "         m1_n = t0.dayofweek<5         \n",
    "         m2 = t0.hour\n",
    "         trend=self.l+self.b*np.arange(len(y))\n",
    "         season=self.s[m1.astype(int),m2]\n",
    "         ypred = trend+season\n",
    "\n",
    "         eps = y-ypred\n",
    "         eps_l = np.mean(eps)\n",
    "         self.l = self.l + self.alpha*eps_l\n",
    "         eps=eps-eps_l\n",
    "         eps_b = (eps[-1]-eps[0])/len(eps)\n",
    "         self.b = self.b + self.beta*eps_b\n",
    "         eps=eps-eps_b*np.arange(len(eps))\n",
    "         ds = np.dot(self.gamma(),np.array([m1_n,m1]))*[eps,eps]\n",
    "         self.s = self.s + ds\n",
    "         ytot=pd.Series(ypred,index=y.index)\n",
    "         return ytot\n",
    "\n",
    "    def STL_dayahead(self,y,ninit=4*24*7):\n",
    "         \"\"\"STL_dayahead\n",
    "         Predict day-ahead demand given previous parameters.\n",
    "         Then update parameters given true demand.\n",
    "         \"\"\"\n",
    "         self.fit_init_params(y,ninit=ninit)\n",
    "         t0=y.index[0]\n",
    "         m1 = t0.dayofweek>=5\n",
    "         m2 = t0.hour\n",
    "         ypred = np.zeros(len(y))\n",
    "         ti = y[:ninit].index\n",
    "         msk=ti.dayofweek>=5\n",
    "         ypred[:ninit] = self.l+self.b*np.arange(ninit) \\\n",
    "                  + self.s[msk.astype(int),ti.hour.values]\n",
    "                  \n",
    "         for i in range(int(ninit/24),int(len(y)/24)):\n",
    "             tslice = slice(i*24,(i+1)*24)\n",
    "             ypred[tslice] = self.predict_correct_dayahead(y[tslice])\n",
    "             \n",
    "         # if i%(24*7) ==0:\n",
    "         #         print(\"l: {} b: {}\\n\".format(str(l),str(b)))\n",
    "         #         print(s,\"\\n\")\n",
    "         ypred=pd.Series(ypred,index=y.index)         \n",
    "         return ypred\n",
    "\n",
    "    def optimize_param(self,y,ninit=4*24*7,rtol=0.01,\\\n",
    "                        eta=0.01,lr=0.05,nmax=100):\n",
    "        \"\"\"optimize_param\n",
    "        Use gradient descent to find optimum parameters for learning \n",
    "        rates alpha,beta,gamma.  Wait till all of their values are \n",
    "        settled to a relative tolerance.\n",
    "        Cost is root Mean Square Error over whole time series.\n",
    "        Currently tries to predict day ahead.  \n",
    "        \"\"\"\n",
    "        self.fit_init_params(y)\n",
    "        #Super clunky way of specifiying names.\n",
    "        #Why did I think this was superior?\n",
    "        names=['alpha','beta','g00','g01','g10','g11']\n",
    "        pred0 = self.STL_dayahead(y,ninit=ninit)\n",
    "        J    = self.rmse(y[ninit:],pred0[ninit:])\n",
    "        Ni=0\n",
    "        #loop over iterations\n",
    "        for i in range(nmax):\n",
    "            dJ_max=0\n",
    "            #for each name, tweak the model's variables.\n",
    "            eta=eta*0.99\n",
    "            for n in names:\n",
    "                p0=self.__getattribute__(n)            \n",
    "                self.__setattr__(n,p0*(1+eta))\n",
    "                #print(n,p0,p0*(1+eta))\n",
    "                pred=self.STL_dayahead(y,ninit=ninit)\n",
    "                J2=self.rmse(y[ninit:],pred[ninit:])\n",
    "                dJ = np.abs((J2-J)/J)\n",
    "                # if (debug):\n",
    "                #     print('J,J2,p',J,J2,p0)\n",
    "                #actually update \n",
    "                #p = p0-lr*(J2-J)/(eta*p0)\n",
    "                p = p0+lr*dJ/(eta*p0)\n",
    "                if (p>1):\n",
    "                    print('param {} >1(!): {}'.format(n,p))\n",
    "                    print('J,J2,p',J,J2,p0)\n",
    "                    p=min(p0+0.5*(1-p0),0.99)\n",
    "                elif(p<0): \n",
    "                    print('param {} <0(!): {}'.format(n,p))\n",
    "                    print('J,J2,p',J,J2,p0)\n",
    "                    p=0.5*p0\n",
    "                self.__setattr__(n,p)\n",
    "                J=J2\n",
    "                dJ_max=max(dJ,dJ_max)\n",
    "            Ni+=1       \n",
    "            if (dJ_max<rtol):\n",
    "               print(\"Hit tolerance {} at iter {}\".format(dJ,Ni))\n",
    "               plot_pred([pred,y],['Predicted','Actual'])               \n",
    "               return pred\n",
    "            if(Ni%10==0):\n",
    "                print(\"Cost, Old Cost = {},{}\".format(J,J2))\n",
    "                plot_pred([pred,y],['Predicted','Actual'])\n",
    "                for n in names:\n",
    "                    p0=self.__getattribute__(n)\n",
    "                    print(n,p0)\n",
    "\n",
    "        print(\"Failed to hit tolerance after {} iter\\n\".format(iter))\n",
    "        print(\"Cost:\",J,J2)\n",
    "        return pred \n",
    "\n",
    "    def root_optimize_param(self,y,ninit=4*24*7,rtol=0.01,\\\n",
    "                        eta=0.2,lr=0.1,nmax=100):\n",
    "        \"\"\"root_optimize_param\n",
    "        Use simple root-finding to find the minimum error to optimize  \n",
    "        the parameters for alpha,beta,gamma.\n",
    "        \n",
    "        Based on data, and for chosen func, which predicts all values \n",
    "        of y.  Pick one with minimum Mean Squared Error.\n",
    "        \"\"\"\n",
    "        self.fit_init_params(y)\n",
    "        #Specify parameters to search over.  \n",
    "        names=['alpha','beta','g00','g01','g10','g11']\n",
    "        pred0 = self.STL_dayahead(y,ninit=ninit)\n",
    "        J    = self.rmse(y[ninit:],pred0[ninit:])\n",
    "        Ni=0\n",
    "        #loop over iterations\n",
    "        for i in range(nmax):\n",
    "            dJ_max=0\n",
    "            #for each name, tweak the model's variables.\n",
    "            eta=eta*0.99\n",
    "            for n in names:\n",
    "                p0=self.__getattribute__(n)            \n",
    "                self.__setattr__(n,p0*(1+eta))\n",
    "                print(n,p0,p0*(1+eta))\n",
    "                pred=self.STL_dayahead(y,ninit=ninit)\n",
    "                J2=self.rmse(y[ninit:],pred[ninit:])\n",
    "                dJ = np.abs((J2-J)/J)\n",
    "                J=J2\n",
    "                dJ_max=max(dJ,dJ_max)\n",
    "                #actually update \n",
    "                self.__setattr__(n,p)\n",
    "            Ni+=1       \n",
    "            if (dJ_max<rtol):\n",
    "               print(\"Hit tolerance {} at iter {}\".format(dJ,Ni))\n",
    "               plot_pred([pred,y],['Predicted','Actual'])               \n",
    "               return pred\n",
    "            if(Ni%10==0):\n",
    "                print(\"Cost, Old Cost,Max = {},{},{}\".format(J,J2,dJ_max))\n",
    "                plot_pred([pred,y],['Predicted','Actual'])   \n",
    "        print(\"Failed to hit tolerance after {} iter\\n\".format(iter))\n",
    "        print(\"Cost:\",J,J2)\n",
    "        return pred \n",
    "\n",
    "\n",
    "    def rmse(self,x,y):\n",
    "        \"\"\"compute mean_square_error\"\"\"\n",
    "        z = np.sum( (x-y)*(x-y))/len(x)\n",
    "        z = np.sqrt(z)\n",
    "        return z\n",
    "#End of Class\n",
    "def scale_data(D,T):\n",
    "    \"\"\"scale_data\n",
    "    Scales both demand and temperature to have zero mean, \n",
    "    unit standard deviation.\n",
    "    Returns scaled data, as well as means, and standard deviations.\n",
    "    \"\"\"\n",
    "    scaling_df=pd.DataFrame(columns=['dem','temp'],index=['mu','std'])\n",
    "    scaling_df.loc['mu','dem']=D.mean()\n",
    "    scaling_df.loc['std','dem']=D.std()\n",
    "    scaling_df.loc['mu','temp']=T.mean()\n",
    "    scaling_df.loc['std','temp']=T.std()\n",
    "    T_scale=(T-T.mean())/T.std()\n",
    "    D_scale=(D-D.mean())/D.std()\n",
    "    return D_scale,T_scale,scaling_df\n",
    "\n",
    "def plot_pred(series_list,label_list):\n",
    "    \"\"\"make plot to compare fitted parameters\"\"\"\n",
    "    for s,l in zip(series_list,label_list):\n",
    "        plt.plot(s,label=l)    \n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The following code tries to optimize the hyperparameters.  It seems to lock onto essentially a persistence model.  The best guess is to just use yesterday's electricity usage to predict today's. (Considering that was going to be my benchmark for simple and effective, this is somewhat disheartening.\n",
    "\n",
    "I tried this numerically rather than via directly coding up gradient descent, since the closed form derivatives become nasty polynomials in the parameters $(\\alpha,\\beta,\\gamma)$. The previous values $y_{t-1}$ also depend on the choice of parameters, so when you consider the derivative of the cost function\n",
    "$\\partial_\\alpha J = T^{-1}\\sum_t \\partial_\\alpha(y_t-\\hat{y}_t)$ there is a nested sum of terms (since the parameter estimates rely on the previous errors too)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "start = 24*7*30\n",
    "end =  start+24*7*4+24*7*20\n",
    "dem_sub = dem[start:end]\n",
    "temp_sub = temp[start:end]\n",
    "fore_sub = fore[start:end]\n",
    "\n",
    "alpha=0.3\n",
    "beta=0.2\n",
    "gamma=0.04*np.array([[1,0.4],[0.4,1]])\n",
    "global icount\n",
    "icount=0\n",
    "ms_model=ms(alpha=alpha,beta=beta,gamma=gamma)\n",
    "ytot=ms_model.STL_onestep(dem_sub)\n",
    "\n",
    "alpha2=0.1\n",
    "beta2=0.1\n",
    "gamma2=0.1*np.array([[1,0.2],[0.2,1]])\n",
    "ms_model2=ms(alpha=alpha2,beta=beta2,gamma=gamma2)\n",
    "ytot2=ms_model2.STL_dayahead(dem_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 0.99\n",
      "beta 0.985147928986\n",
      "g00 0.99\n",
      "g01 0.99\n",
      "g10 0.991569674802\n",
      "g11 0.99\n",
      "Failed to hit tolerance after <built-in function iter> iter\n",
      "\n",
      "Cost: 168.316319889 168.316319889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbb438dbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param g11 >1(!): 1.0353776240021706\n",
      "J,J2,p 169.695206208 168.316319889 0.99\n",
      "Cost, Old Cost = 168.31631988930127,168.31631988930127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param g01 >1(!): 1.0390300512948585\n",
      "J,J2,p 168.228636805 169.705633112 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param g00 >1(!): 1.0032790565819971\n",
      "J,J2,p 168.416992255 168.228636805 0.997077777089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param alpha >1(!): 1.0001353097919528\n",
      "J,J2,p 168.298348873 168.603794575 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param g11 >1(!): 1.0280524150688624\n",
      "J,J2,p 169.464738132 168.298348873 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param g01 >1(!): 1.017575102584343\n",
      "J,J2,p 168.64199501 169.483128277 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param alpha >1(!): 1.0050613145649414\n",
      "J,J2,p 168.617330999 169.000780761 0.992520667186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param g11 >1(!): 1.0341501757621565\n",
      "J,J2,p 169.988524633 168.617330999 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param g01 >1(!): 1.03035451184613\n",
      "J,J2,p 168.756293298 170.000518011 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param g00 >1(!): 1.0013167359769515\n",
      "J,J2,p 169.105937869 168.756293298 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param g11 >1(!): 1.0339200718467978\n",
      "J,J2,p 170.794652628 169.260481011 0.985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param g01 >1(!): 1.0275075898213326\n",
      "J,J2,p 169.628099207 170.802262518 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param g00 >1(!): 1.006922353392223\n",
      "J,J2,p 170.313665186 169.628099207 0.985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param alpha >1(!): 1.000187324620615\n",
      "J,J2,p 171.387736644 170.710767652 0.978533379572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param g11 >1(!): 1.045474639156655\n",
      "J,J2,p 173.783380102 171.387736644 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param g10 >1(!): 1.006707998366998\n",
      "J,J2,p 173.243796833 173.783380102 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param g01 >1(!): 1.0098476459975672\n",
      "J,J2,p 172.505250635 173.243796833 0.986806602803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param g00 >1(!): 1.0209721313530784\n",
      "J,J2,p 174.12635208 172.505250635 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param alpha >1(!): 1.0990423142460877\n",
      "J,J2,p 179.320859608 174.732813399 0.957066759143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param g11 >1(!): 1.0379938871965098\n",
      "J,J2,p 182.518575522 179.320859608 0.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param g10 >1(!): 1.1116386575901311\n",
      "J,J2,p 178.19612068 182.518575522 0.981731346774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param g01 >1(!): 1.0713099797689924\n",
      "J,J2,p 181.479339576 178.19612068 0.973613205606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param g00 >1(!): 1.0812113062053545\n",
      "J,J2,p 186.179749496 181.479339576 0.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param alpha >1(!): 2.280522286213759\n",
      "J,J2,p 245.552837439 187.217079849 0.914133518286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param g11 >1(!): 3.357713943778967\n",
      "J,J2,p 173.05926924 245.552837439 0.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param g01 >1(!): 1.0987441783478669\n",
      "J,J2,p 174.731218838 169.913309304 0.947226411211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param g00 >1(!): 1.041348240369465\n",
      "J,J2,p 179.631258464 174.731218838 0.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param alpha >1(!): 4.726308120488169\n",
      "J,J2,p 478.505642912 181.698309273 0.828267036573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param g11 >1(!): 13.126352439501156\n",
      "J,J2,p 169.451086895 478.505642912 0.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param g00 >1(!): 1.0956649967098968\n",
      "J,J2,p 169.239569753 160.861245976 0.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param alpha >1(!): 6.1415576841303725\n",
      "J,J2,p 575.4921679 173.321151593 0.656534073146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param g11 >1(!): 23.315509546237273\n",
      "J,J2,p 173.155581164 575.4921679 0.52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param g01 >1(!): 1.0083119188056082\n",
      "J,J2,p 162.032274858 170.104745524 0.508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param g00 >1(!): 1.6489720158796475\n",
      "J,J2,p 183.103158095 162.032274858 0.52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param beta >1(!): 1.5518498873543043\n",
      "J,J2,p 196.780109595 183.103158095 0.278446467027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param alpha >1(!): 16.60663284451791\n",
      "J,J2,p 1915225.20041 196.780109595 0.313068146291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param g11 >1(!): 1245610.8252170554\n",
      "J,J2,p 194.119107324 1915225.20041 0.04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param g10 >1(!): 10.286301217387415\n",
      "J,J2,p 188.002208391 194.119107324 0.016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param g01 >1(!): 26.414105547722347\n",
      "J,J2,p 173.493118009 188.002208391 0.016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param g00 >1(!): 2.199168306879345\n",
      "J,J2,p 176.511574126 173.493118009 0.04\n"
     ]
    }
   ],
   "source": [
    "debug=True\n",
    "ms_model2=ms(alpha=alpha2,beta=beta2,gamma=gamma2)\n",
    "ypred=ms_model.optimize_param(dem_sub,rtol=1E-6,nmax=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "672"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "names=['alpha','g00']\n",
    "\n",
    "val=[]\n",
    "for n in names:\n",
    "    val.append(ms_model.__getattribute__(n))\n",
    "\n",
    "blah = [ms_model.__getattribute__(name) for name in names]\n",
    "?ms_model.__setattr__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['STL_dayahead',\n",
       " 'STL_onestep',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'alpha',\n",
       " 'b',\n",
       " 'beta',\n",
       " 'fit_init_params',\n",
       " 'g00',\n",
       " 'g01',\n",
       " 'g10',\n",
       " 'g11',\n",
       " 'gamma',\n",
       " 'l',\n",
       " 'mse',\n",
       " 'optimize_param',\n",
       " 'predict_correct_dayahead',\n",
       " 'predict_correct_onestep',\n",
       " 's']"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(ms_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7fe40c0e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "per=slice(None,'2016-05-15')\n",
    "plt.plot(ytot[per],'b',label='My Predicted')\n",
    "plt.plot(fore_sub[per],'g',label='Actual Predicted')\n",
    "plt.plot(dem_sub[per],'r',label='Actual')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbc24d60b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.cumsum(ytot-fore))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9e5e386278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l,b,s=ms.fit_init_params(dem_sub,ninit=4*24*7)\n",
    "plt.plot(s.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Thresholded Temperature Model\n",
    "\n",
    "Let's just try to build a linear model for the temperature on top of this.\n",
    "I'll assume that heating/cooling might have different coefficients, so the temperature component of the model at time $t$ is\n",
    "\\begin{equation}\n",
    "D_t =  a_0+ a_+[T_t-T_{+}]_{+} + a_-[T_{-}-T_t]_{+},\n",
    "\\end{equation}\n",
    "where $[f]_+=f$ if $f>0$, and is zero otherwise.  If we optimize the mean square\n",
    "error, then the components can be found by solving for the values that minimize the derivatives.\n",
    "If criteria is mean square error, then can solve directly for parameters\n",
    "$J = sum_t[\\hat{D}_t-D_t)^2$, where $\\hat{D}_t$ is the true value.\n",
    "We must solve $\\partial J/\\partial \\alpha = 0 \\rightarrow \\sum_t \\frac{\\partial D_t}{\\partial\\alpha}(\\hat{D}_t-D_t) $\n",
    "\n",
    "Those conditions are\n",
    "\\begin{align}\n",
    "    \\sum_t(\\hat{D}_t-D_t)=0  \\qquad (a_0)\\\\\n",
    "    \\sum_{t\\in T_\\pm}[T_t-T_\\pm]_\\pm(\\hat{D}_t-D_t)=0  \\qquad (a_\\pm)\\\\\n",
    "    \\sum_{t\\in T_\\pm}(\\pm a_{\\pm})(\\hat{D}_t-D_t)=0  \\qquad (T_\\pm)\\\\\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "(First OOP class - absolutely ridiculous)  Will just use a pandas Dataframe - want a named set of numbers, with defined operations.  Already here.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Experimenting with OOP for making \"vector\" of parameters with named labels.\n",
    "#Feels daft - if there's a less stupid way, I'll try to fix this.  (Just use a Dataframe!?)\n",
    "#Initial attempts at getting smarter initialization (with arguments to make a dict just returned empty.\n",
    "# class param_vec(dict):\n",
    "#     \"\"\"Class for model parameters.\n",
    "#     Stores parameters in dict, with arithmatic operations.\n",
    "#     \"\"\"\n",
    "#     #Define elementwise subtraction/addition\n",
    "#     def __add__(self,x):\n",
    "#         y = self.copy()\n",
    "#         if isinstance(x,(int,float)):\n",
    "#             for i,v in self.items():\n",
    "#                 y[i]=self[i]+x\n",
    "#         else:\n",
    "#             for i,v in self.items():\n",
    "#                 y[i]=self[i]+x[i]\n",
    "#         return param_vec(y)\n",
    "\n",
    "#     #Define elementwise subtraction/addition\n",
    "#     def __radd__(self,x):\n",
    "#         return param_vec.__add__(self,x)\n",
    "    \n",
    "#     #Define elementwise subtraction.\n",
    "#     def __sub__(self,x):\n",
    "#         y=self.copy()\n",
    "#         if isinstance(x,(int,float)):\n",
    "#             for i,v in self.items():\n",
    "#                 y[i]=v-x\n",
    "#         else:        \n",
    "#             for i,v in self.items():\n",
    "#                 y[i]=v-x[i]\n",
    "#         return param_vec(y)\n",
    "                \n",
    "#     #Define elementwise subtraction/addition\n",
    "#     def __rsub__(self,x):\n",
    "#         return param_vec.__sub__(self,x)\n",
    "                \n",
    "#     #Define elementwise subtraction.\n",
    "#     def __truediv__(self,x):\n",
    "#         y=self.copy()\n",
    "#         if isinstance(x,(int,float)):\n",
    "#             for i,v in self.items():\n",
    "#                 y[i]=v/x\n",
    "#         else:        \n",
    "#             for i,v in self.items():\n",
    "#                 y[i]=v/x[i]\n",
    "#         return param_vec(y)\n",
    "                \n",
    "#     #Define elementwise subtraction.\n",
    "#     def __mul__(self,x):\n",
    "#         y=self.copy()\n",
    "#         if isinstance(x,(int,float)):\n",
    "#             for i,v in self.items():\n",
    "#                 y[i]=v*x\n",
    "#         else:        \n",
    "#             for i,v in self.items():\n",
    "#                 y[i]=v*x[i]\n",
    "#         return param_vec(y)\n",
    "                \n",
    "#     #Define elementwise subtraction.\n",
    "#     def __rmul__(self,x):\n",
    "#         return param_vec.__mul__(self,x)\n",
    "\n",
    "def param_vec(names,vals):\n",
    "    p=pd.Series(vals,index=names)\n",
    "    return p\n",
    "\n",
    "#might extend to contain all of the modelling stuff?          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "dem_sub  = dem[0:24*7*1]\n",
    "temp_sub = temp[0:24*7*1]\n",
    "\n",
    "D=dem_sub\n",
    "T=temp_sub\n",
    "Dr = np.max(D)-np.min(D)\n",
    "Tr = np.max(T)-np.min(T)\n",
    "\n",
    "pnames=['a0','ap','an','Tp','Tn']\n",
    "pval=[np.mean(D),0.5*Dr/Tr,0.5*Dr/Tr,200,100]\n",
    "\n",
    "Tmodel=just_temp_model(names=pnames,vals=pval)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class just_temp_model:\n",
    "    def __init__(self,names=[],vals=[]):\n",
    "        self.param= pd.Series(vals,index=names)\n",
    "\n",
    "    def temp_model(self,T):\n",
    "        \"\"\"temp_model(self,T)\n",
    "        Tries to fit linear model for electricity demand to temperature.\n",
    "        Initially tried to allow thresholding, and different slopes for heating/cooling.  \n",
    "        Will now just try simpler linear model a_p|T-T_p|.\n",
    "        \"\"\" \n",
    "        m1 = T>self.param['Tp']\n",
    "        m2 = T<self.param['Tn']\n",
    "        y=np.zeros(T.shape)\n",
    "        y[m1] = (T[m1]-self.param['Tp'])*self.param['ap']\n",
    "        y[m2] = (self.param['Tn']-T[m2])*self.param['an']\n",
    "        y=y+self.param['a0']\n",
    "        #y = param['a0']+ param['ap']*np.abs(T-param['Tp'])\n",
    "        y=pd.Series(y,name='Predicted Demand',index=T.index)\n",
    "        return y\n",
    "\n",
    "    def temp_model_grad(self,D,Dhat,T):\n",
    "        \"\"\"temp_model_grad\n",
    "        Compute gradients of model w.r.t. parameters.\n",
    "        Assumes loss-function is mean-square.\n",
    "        Dhat - measured demand\n",
    "        D    - predicted demand\n",
    "        T    - measured temperature\n",
    "        \"\"\"\n",
    "        m1 = T>self.param['Tp']\n",
    "        m2 = T<self.param['Tn']\n",
    "        Nt = len(T)\n",
    "        Derr=D-Dhat\n",
    "        #initialize with zeros\n",
    "        dparam=param_vec(self.param.keys(),np.zeros(len(self.param)))\n",
    "        dparam['a0'] = np.sum(Derr)/Nt\n",
    "        #Single model\n",
    "        # dparam['ap'] = np.sum( np.abs(T-param['Tp'])*Derr)/Nt\n",
    "        # dparam['Tp'] = -np.sum(np.sign(T-param['Tp'])*param['ap']*Derr)/Nt\n",
    "        #Double thresholded model\n",
    "        dparam['ap'] = np.sum( np.abs(T[m1]-self.param['Tp'])  \\\n",
    "                     *(Derr[m1]))/Nt\n",
    "        dparam['an'] = np.sum( (self.param['Tn']-T[m2])*(Derr[m2]))/Nt\n",
    "        dparam['Tp'] = -self.param['ap']*np.sum(Derr[m1])/Nt\n",
    "        dparam['Tn'] =  self.param['an']*np.sum(Derr[m2])/Nt    \n",
    "        return dparam\n",
    "    \n",
    "    def param_fit(self,Dhat,T,alpha=0.1,rtol=1E-4,nmax=200):\n",
    "        \"\"\"Try to fit linear threshold model of demand to temperature.\n",
    "            D - demand data\n",
    "            T - temperature data\n",
    "            Fits model of form:\n",
    "            D ~ a_0+ a_p[T-T_p]_+ + a_n[T_n-T]_+,\n",
    "            where [f]_+ =f for f>0, and 0 otherwise.\n",
    "\n",
    "            Just use simple gradient descent to fit the model.\n",
    "        \"\"\"\n",
    "        #make parameter estimates\n",
    "        Dr = np.max(Dhat)-np.min(Dhat)\n",
    "        Tr = np.max(T)-np.min(T)\n",
    "        param_names=['a0','ap','an','Tp','Tn']\n",
    "        param_vals=[np.mean(Dhat), 0.5*Dr/Tr, 0.5*Dr/Tr,\n",
    "        np.mean(T), np.mean(T)]\n",
    "        self.param=param_vec(param_names,param_vals)\n",
    "        Dpred = self.temp_model(T)\n",
    "        J=np.sum((Dpred-Dhat)**2)/len(Dhat)\n",
    "        print('Init cost',J)\n",
    "        plot_pred(Dpred,Dhat,T)\n",
    "        print('Param:',self.param,\"\\n\")    \n",
    "\n",
    "        Ni=0\n",
    "        for i in range(nmax):\n",
    "            dparam=self.temp_model_grad(Dpred,Dhat,T)\n",
    "            self.param=self.param-alpha*dparam\n",
    "            Dpred=self.temp_model(T)\n",
    "            J2=J        \n",
    "            J=np.sum((Dpred-Dhat)**2)/len(Dhat)\n",
    "            err_change=abs(1-J2/J)\n",
    "            Ni+=1\n",
    "            if (err_change<rtol):\n",
    "               print(\"Hit tolerance {} at iter {}\".format(\n",
    "               err_change,Ni))\n",
    "               plot_pred(Dpred,Dhat,T)                      \n",
    "               return Dpred\n",
    "            if(Ni%100==0):\n",
    "                print(\"Cost, Old Cost = {},{}\".format(J,J2))\n",
    "                print('Param:',self.param)\n",
    "                print('Param_grad:',dparam)\n",
    "                print(\"Mean param Change {} at iter {}\".format(err_change,Ni))\n",
    "                plot_pred(Dpred,Dhat,T)\n",
    "        print(\"Failed to hit tolerance after {} iter\\n\".format(iter))\n",
    "        print(\"Cost:\",J,J2)\n",
    "        return Dpred \n",
    "\n",
    "    def grad_check(self,Dhat,T):\n",
    "        \"\"\"grad_check(Dhat,T)\n",
    "        Check numerical gradients against finite difference.\n",
    "            D - demand data\n",
    "            T - temperature data\n",
    "        \"\"\"\n",
    "        #make parameter estimates\n",
    "        Dr = np.max(Dhat)-np.min(Dhat)\n",
    "        Tr = np.max(T)-np.min(T)\n",
    "        param_names=['a0','ap','an','Tp','Tn']\n",
    "        #param_vals=300*np.random.random(size=5)\n",
    "        param_vals=[np.mean(D),0.5*Dr/Tr,0.5*Dr/Tr,200,250]        \n",
    "        self.param=param_vec(param_names,param_vals)\n",
    "        print(self.param)\n",
    "        Dpred = self.temp_model(T)    \n",
    "        dparam=self.temp_model_grad(Dpred,Dhat,T)    \n",
    "        J=0.5*np.sum((Dpred-Dhat)**2)/len(Dhat)\n",
    "        eps=.1\n",
    "        param2 = self.param.copy()\n",
    "        for name,val in param2.items():\n",
    "            self.param = param2.copy()\n",
    "            self.param[name]=val+eps\n",
    "            Dpred = self.temp_model(T)\n",
    "            J2=0.5*np.sum((Dpred-Dhat)**2)/len(Dhat)\n",
    "            numgrad = (J2-J)/eps\n",
    "            print(name,numgrad,dparam[name],self.param[name])\n",
    "\n",
    "#End of temp_model class.\n",
    "#Needed to scale the data to get decent answers.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a0    1.831868e-16\n",
      "ap    4.540773e+00\n",
      "an    4.540773e+00\n",
      "Tp    2.000000e+02\n",
      "Tn    2.500000e+02\n",
      "dtype: float64\n",
      "a0 -2233.0354153411463 -2233.08541539 0.1\n",
      "ap -76396.42076404765 -90916.6982743 4.64077253219\n",
      "an -74030.27359302621 -74171.064218 4.64077253219\n",
      "Tp 3705.3657396975905 6423.67484413 200.1\n",
      "Tn 130837.66448286362 -6434.87400116 250.1\n"
     ]
    }
   ],
   "source": [
    "dem_sub  = dem[0:24*7*4]\n",
    "temp_sub = temp[0:24*7*4]\n",
    "#D,T,scale_df=scale_data(dem_sub,temp_sub)\n",
    "Tmodel=just_temp_model(names=pnames,vals=pval)\n",
    "Tmodel.grad_check(dem_sub,temp_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(temp_sub<Tmodel.param['Tn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Fourier Series\n",
    "\n",
    "Another approach that I've seen to seasonality is to just use a Fourier series.\n",
    "This is similar to an approach I was using based on trying to filter the Fourier tranformed data.\n",
    "This method tries to fit annual, weekly and daily oscillations to the data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Now to do some simple Fourier Series fitting too.\n",
    "class fourier_model:\n",
    "    def total_fourier_series(self,D,n_max=[2,4,4]):\n",
    "        \"\"\"fourier_series\n",
    "        Fits pandas time series D, with Fourier series. \n",
    "        Uses Pandas DateTimeIndex for times.\n",
    "        Produces fourier series with annual, daily and weekly oscillations to fourier series.\n",
    "        Computes coefficients, and then series.  Returns both\n",
    "        D - demand (values to be fitted)\n",
    "        T - DatetimeIndex\n",
    "        n_max - maximum number of coefficients\n",
    "\n",
    "        Note:Misses Holidays.\n",
    "        \"\"\"\n",
    "        T=D.index\n",
    "        T_dayofyear = T.dayofyear.values\n",
    "        T_dayofweek = T.dayofweek.values\n",
    "        T_hour = T.hour.values\n",
    "        Tfit = [T_dayofyear/365,\n",
    "        (T_dayofweek*24+T_hour)/168,\n",
    "        T_hour/24]\n",
    "        periods=[365,168,24]\n",
    "        Nt = len(D)\n",
    "        ftot = np.zeros(Nt)\n",
    "        coeff=[[np.sum(D)/Nt,0]]    \n",
    "        for i in range(3):\n",
    "            if n_max[i]>0:\n",
    "                 ci    = self.fit_fourier_series(D,Tfit[i],n_max[i])\n",
    "                 ftot += self.fourier_series(ci,Tfit[i])             \n",
    "            else:\n",
    "                ci=None\n",
    "            coeff.append(ci)\n",
    "        #add on constant    \n",
    "        ftot+= coeff[0][0]\n",
    "        ftot=pd.Series(ftot,index=T)         \n",
    "        return ftot,coeff\n",
    "\n",
    "    def fit_fourier_series(self,D,T,nmax):\n",
    "        \"\"\"Fits the Fourier series to data D, on times T,\n",
    "        and returns parameters.\n",
    "        \"\"\"\n",
    "        Nt = len(D)\n",
    "        #initial zero coefficients\n",
    "        coeff=[]\n",
    "        for n in range(1,nmax+1):\n",
    "            an= 2*np.sum(np.cos(2*pi*n*T)*D)/Nt\n",
    "            bn= 2*np.sum(np.sin(2*pi*n*T)*D)/Nt\n",
    "            coeff.append([an,bn])\n",
    "        return coeff                       \n",
    "\n",
    "    def fourier_series(self,coeff,T):\n",
    "        \"\"\"fourier_series\n",
    "        Make simple Fourier series with specified coefficients, \n",
    "        over time T. \n",
    "        T assumed to be in range [0,1).\n",
    "        \"\"\"\n",
    "        i=1\n",
    "        nmax=len(coeff)\n",
    "        f=np.zeros(T.shape)\n",
    "        #need a +1 somewhere due to 0-indexing, and not including constant\n",
    "        for n in range(nmax):\n",
    "            an, bn = coeff[n]\n",
    "            f += an*np.cos(2*pi*(n+1)*T)+bn*np.sin(2*pi*(n+1)*T)\n",
    "        return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'builtin_function_or_method' object has no attribute 'dayofyear'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-4c0d5c2054ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mDf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDcoeff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfourier_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_fourier_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdem_sub\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplot_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdem_sub\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemp_sub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-e4828b0b79a2>\u001b[0m in \u001b[0;36mtotal_fourier_series\u001b[0;34m(self, D, n_max)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \"\"\"\n\u001b[1;32m     15\u001b[0m         \u001b[0mT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mT_dayofyear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdayofyear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mT_dayofweek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdayofweek\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mT_hour\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhour\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'dayofyear'"
     ]
    }
   ],
   "source": [
    "dem_sub  = dem[0:24*7*4]\n",
    "temp_sub = 10*temp[0:24*7*4]\n",
    "\n",
    "nmax = [0,4,4]\n",
    "\n",
    "Df, Dcoeff = fourier_model.total_fourier_series(dem_sub,nmax)\n",
    "plot_pred(Df,dem_sub,temp_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dem_scale.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to hit tolerance after <built-in function iter> iter\n",
      "\n",
      "Cost: 0.06780300101098831 0.06784870959652975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbc189a588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost, Old Cost = 0.06780300101098831,0.06784870959652975\n",
      "Param: a0   -0.355393\n",
      "ap    0.739753\n",
      "an   -0.714479\n",
      "Tp   -0.859248\n",
      "Tn   -0.143258\n",
      "dtype: float64\n",
      "Param_grad: a0   -0.002524\n",
      "ap    0.002695\n",
      "an    0.010862\n",
      "Tp    0.002000\n",
      "Tn    0.007561\n",
      "dtype: float64\n",
      "Mean param Change 0.0006741380891686077 at iter 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbc188ce10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost, Old Cost = 0.07670151030736305,0.07687407174663803\n",
      "Param: a0   -0.391960\n",
      "ap    0.838400\n",
      "an   -0.585513\n",
      "Tp   -0.690012\n",
      "Tn   -0.059845\n",
      "dtype: float64\n",
      "Param_grad: a0   -0.006662\n",
      "ap    0.017932\n",
      "an    0.016383\n",
      "Tp    0.028599\n",
      "Tn    0.008011\n",
      "dtype: float64\n",
      "Mean param Change 0.00224977889722755 at iter 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param: a0    1.831868e-16\n",
      "ap    4.542121e-01\n",
      "an    4.542121e-01\n",
      "Tp    2.164935e-16\n",
      "Tn    2.164935e-16\n",
      "dtype: float64 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbc180fbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init cost 1.0263110440225278\n"
     ]
    }
   ],
   "source": [
    "dem_scale,temp_scale,scale_df=scale_data(dem_sub,temp_sub)\n",
    "plt.figure()\n",
    "Dpred=Tmodel.param_fit(dem_scale,temp_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 8\n"
     ]
    }
   ],
   "source": [
    "l,b,s=fit_init_params(dem_sub)\n",
    "\n",
    "pred=predict_stl(l,b,s,dem_sub.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9e6058f630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dem_sub.values,'b',temp_sub.values,'r',pred,'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Rambling Time!\n",
    "\n",
    "From a Kalman filter perspective, I think that sometimes the error/innovation terms can be written as $\\epsilon_t = y_t-\\hat{y}_t$, where $y_t$ is the actual value, and $\\hat{y}_t$ is the output of the model with no noise.  The innovation process, then gives a rule for updating (the set of parameters $\\alpha,\\beta,\\Gamma, l, b, s_{i,t}$) how to change in the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%pdb"
   ]
  }
 ],
 "metadata": {
  "name": "EBA_seasonal.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
