{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Seasonal Regression\n",
    "\n",
    "The electricity demand series shows daily, weekly, and annual oscillations.  At a short time scale, I aim to capture the first two of these.\n",
    "\n",
    "The approaches I've seen suggest Fourier Series, linear regression, and Seasonal ARIMA.\n",
    "(I got quite stuck on how to detrend the series in a global fashion.)\n",
    "I will focus on building models on the last two weeks of data, with the goal of predicting electricity demand based on temperature, time of day, and day of week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Hyndman's Multiple Seasonal Exponential Smoothing\n",
    "\n",
    "This follows Rob Hyndman's approach towards multi-seasonal exponential smoothing.  (This generalizes the apparently well-known Holt-Winters smoothing).\n",
    "His analysis includes forecasts of electricity generation, based on utility data (from well over 10 years ago).  \n",
    "\n",
    "The original model for a variable $y_t$, with seasonal pattern with period $m$ is\n",
    "\\begin{align}\n",
    "  y_t &= l_{t-1}+b_{t-1} +s_{t-m} +\\epsilon_t\\\\\n",
    "  l_t &= l_{t-1} + \\alpha\\epsilon_t\\\\\n",
    "  b_t &= b_{t-1} + \\beta\\epsilon_t\\\\\n",
    "  s_{t} = s_{t-m} + \\gamma \\epsilon_t\n",
    "\\end{align}\n",
    "where $l_t$, b_t,s_t$ are the level, trend and seasonal patterns respectively.\n",
    "The noise is Gaussian and obeys\n",
    "$E[\\epsilon_t]=0, E[\\epsilon_t\\epsilon_s]=\\delta_{ts}\\sigma^2$, and $\\alpha,\\beta,\\gamma$ are constants between zero and one.  (He notes that $m+2$ estimates must be made for the initial values of the level, trend and seasonal pattern).\n",
    "\n",
    "Hyndman's model allows multiple seasons, and allows the sub-seasonal terms to be updated more quickly than once per large season.  In utility data, the short season is the daily oscillation, while the longer season comes from the weekly oscillation induced by the work week.  For hourly data, the daily cycle has length $m_1=24$, with the weekly cycle taking $m_2=168$.  The ratio between them is $k=m_2/m_1=7.$  The number of seasonal patterns is $r\\le k$.  \n",
    "\n",
    "(I'm going to change Hyndman's notation to use $\\mathbf{I}$ to denote indicator/step functions).\n",
    "\\begin{align}\n",
    "  y_t &= l_{t-1}+b_{t-1} +\\sum_{i=1}^r \\mathbf{I}_{t,i}s_{i,t-m_1} +\\epsilon_t\\\\\n",
    "  s_{i,t} = s_{i,t-m_1} + \\sum_{j=1}^r\\left(\\gamma_{ij}\\mathbf{I}_{t,j}\\right) \\epsilon_t  (i=1,2,\\ldots,r)\n",
    "  l_t &= l_{t-1} + b_{t-1}+\\alpha\\epsilon_t\\\\\n",
    "  b_t &= b_{t-1} + \\beta\\epsilon_t\\\\\n",
    "\\end{align}\n",
    "Here the indicator functions $\\mathbf{I}_{t,i}$ are unity if $t$ is in the seasonal pattern $i$, and zero otherwise.  For utility data, this will probably be weekday and holiday/weekend.  Here $\\gamma_{ij}$ denotes how much one seasonal pattern is updated based on another---Hyndman proposes a number of restrictions on these parameters.\n",
    "\n",
    "I will extend this to include an external variables for the deviation above a given temperature, so that $y_t\\rightarrow y_t+\\tau_p\\Theta(T_t-T_p)+\\tau_{n}\\Theta(T_n-T_t)$.\n",
    "\n",
    "He suggests using the first four weeks of data to estimate the parameters, by minimizing the squared error of the one-step ahead forecast.  Apparently maximum likelihood estimation was not recommended (10 years ago).\n",
    "\n",
    "So how to fit the parameters?  A really simple approach would be gradient descent?  Intuitively, the level is the average value, the bias is the average gradient.  The seasonality is the average seasonal pattern.  (This is the dumb STL decomposition used earlier?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from get_weather_data import convert_isd_to_df, convert_state_isd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with Mahlon Sweet Field\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with Salem Municipal Airport/McNary Field\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with Portland International Airport\n"
     ]
    }
   ],
   "source": [
    "air_df = pd.read_csv('data/air_code_df.gz')\n",
    "\n",
    "#Just get the weather station data for cities in Oregon.\n",
    "df_weather=convert_state_isd(air_df,'OR')\n",
    "#Select temperature for Portland, OR\n",
    "msk1=np.array(df_weather['city']=='Portland')\n",
    "msk2=np.array(df_weather['state']=='OR')\n",
    "\n",
    "df_pdx_weath=df_weather.loc[msk1&msk2]\n",
    "\n",
    "#get electricity data for Portland General Electric\n",
    "df_eba=pd.read_csv('data/EBA_time.gz',index_col=0,parse_dates=True)\n",
    "msk=df_eba.columns.str.contains('Portland')\n",
    "df_pdx=df_eba.loc[:,msk]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Make a combined Portland Dataframe for demand vs weather.\n",
    "dem=df_pdx.iloc[:,0]\n",
    "df_joint=pd.DataFrame(dem)\n",
    "df_joint=df_joint.join(df_pdx_weath)\n",
    "df_joint['TempShift']=150+abs(df_joint['Temp']-150)\n",
    "df_joint=df_joint.rename(columns={df_joint.columns[0]:'Demand'})\n",
    "#df_joint.head()"
   ]
  }
 ],
 "metadata": {
  "name": "eba_seasonal.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
