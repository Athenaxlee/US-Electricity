{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Recurrent Neural Network\n",
    "\n",
    "Let's try throwing a neural network at this problem. (This was my ultimate goal all along.)  We'll give input method the day of the week, time of day, day of the year, and temperature.  This first version uses a single recurrent cell, with a linear layer at the end.  This could be enhanced by making deeper networks at both the beginning and end, using a fancier cell (LSTM, GRU).\n",
    "\n",
    "The networks will be trained on one year's worth of data, and then tested on the remainder.\n",
    "\n",
    "This desperately needs some regularization (dropout?), as it is overfitting the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## TODO\n",
    "\n",
    "- start using RNN module.\n",
    "- fix the graph to be as desired. \n",
    "- add and fix dropout.  (multiple graphs - train/infer)\n",
    "- extend to allow multiple input/outputs for demand/temp.\n",
    "- visualization for input weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from util.get_weather_data import convert_isd_to_df, convert_state_isd\n",
    "from util.EBA_util import remove_na, avg_extremes\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "from tensorflow.contrib.rnn import BasicRNNCell,LSTMCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with Mahlon Sweet Field\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with Salem Municipal Airport/McNary Field\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with Portland International Airport\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PDX DataFrame from scratch\n"
     ]
    }
   ],
   "source": [
    "#Extend to multiple temperature series\n",
    "try:\n",
    "    gfg\n",
    "    df_joint=pd.read_csv('data/pdx_joint.txt',\n",
    "        index_col=0, parse_dates=True)\n",
    "    print('Read in PDX Frame from file')\n",
    "except:\n",
    "    print('Creating PDX DataFrame from scratch')\n",
    "    air_df = pd.read_csv('data/air_code_df.gz')\n",
    "    #Just get the weather station data for cities in Oregon.\n",
    "    df_weather=convert_state_isd(air_df,'OR')\n",
    "    #Select temperature for Portland, OR\n",
    "    #msk1=np.array(df_weather['city']=='Portland')\n",
    "    msk2=np.array(df_weather['state']=='OR')\n",
    "    df_pdx_weath=df_weather.loc[msk2]\n",
    "    #find number of unique station city/state combinations\n",
    "    Nstation = len(df_pdx_weath['city, state'].unique())\n",
    "\n",
    "    #reshape the single temperature column into Nstation copies.  \n",
    "    unique_station=df_pdx_weath['city, state'].unique()\n",
    "    temp_df=pd.DataFrame()\n",
    "    for station in unique_station:\n",
    "        colname=str('Temp-'+station)\n",
    "        temp_df[colname]=df_pdx_weath.loc[df_pdx_weath['city, state']==station,'Temp']\n",
    "\n",
    "    #get electricity data for Portland General Electric\n",
    "    df_eba=pd.read_csv('data/EBA_time.gz',index_col=0,parse_dates=True)\n",
    "    msk=df_eba.columns.str.contains('Portland')\n",
    "    df_pdx=df_eba.loc[:,msk]\n",
    "    #select out demand data\n",
    "    msk1 = df_pdx.columns.str.contains('[Dd]emand') \n",
    "    dem=df_pdx.loc[:,msk1]\n",
    "    #Make a combined Portland Dataframe for demand vs weather.\n",
    "    df_joint=pd.DataFrame(dem)\n",
    "    df_joint=df_joint.join(temp_df)\n",
    "    df_joint = df_joint.rename(columns={df_joint.columns[0]:'Demand',\n",
    "             df_joint.columns[1]:'Forecast'})\n",
    "    df_joint.to_csv('data/pdx_joint.txt')\n",
    "    \n",
    "dem=df_joint['Demand'].copy()\n",
    "temp=df_joint.loc[:,df_joint.columns.str.contains('Temp')].copy()\n",
    "fore=df_joint['Forecast'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extreme values 1. Number of zero values 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NA values 156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extreme values 0. Number of zero values 143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NA values 126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extreme values 0. Number of zero values 138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NA values 181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extreme values 0. Number of zero values 148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NA values 56\n"
     ]
    }
   ],
   "source": [
    "#clean up data, remove NA\n",
    "#remove NA values, and average extreme values down\n",
    "for y in [temp,dem]:\n",
    "    if len(y.shape)>1:\n",
    "        for i in range(y.shape[1]):\n",
    "            x= y.iloc[:,i]\n",
    "            x = remove_na(x)\n",
    "            y.iloc[:,i] = avg_extremes(x)\n",
    "    else:\n",
    "        x= y\n",
    "        x = remove_na(x)\n",
    "        y = avg_extremes(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def make_temptime_data(temp_mat):\n",
    "    \"\"\"make_input_data\n",
    "    Takes input temperature data matrix (for multiple locations),\n",
    "    and extends with extra indices for time of day, day of year, day of week, and holiday. \n",
    "\n",
    "    Input: temp_mat - pandas series of temperatures a location.  \n",
    "    Output: in_mat - scaled matrix of temperatures, and scaled times of day and year.\n",
    "            temp_max - maximum temperature for series (needed to invert transformations?)\n",
    "            temp_min - minimum temperature\n",
    "    \"\"\"\n",
    "    Tind = temp_mat.index\n",
    "    Nt=len(Tind)\n",
    "    hr = Tind.hour.values/(24-1)\n",
    "    #scale length of year\n",
    "    dyear = Tind.dayofyear.values/(365-1+Tind.is_leap_year.astype(int))\n",
    "    dweek = Tind.dayofweek.values/(7-1)\n",
    "    #scale temperature data to so that max/min correspond to [0,1]  \n",
    "    temp_max = temp_mat.max(axis=0)\n",
    "    temp_min = temp_mat.min(axis=0)\n",
    "    temp_mat = (temp_mat-temp_min)/(temp_max-temp_min)\n",
    "    in_mat=np.stack([hr,dweek,dyear]).T\n",
    "    in_mat= np.hstack([temp_mat.values,in_mat])\n",
    "    return in_mat, temp_max,temp_min\n",
    "\n",
    "def scale_demand(dem):\n",
    "    \"\"\"scale_demand\n",
    "    Scale demand to be on 0,1 scale.\n",
    "    Input: demand - series at single location\n",
    "    Output: dem_scale - scaled array of values.\n",
    "            dem_max, dem_min - the maximum and minimum values.\n",
    "    \"\"\"\n",
    "    dem_scale = dem.values\n",
    "    dem_max = np.max(dem_scale)\n",
    "    dem_min = np.min(dem_scale)\n",
    "    dem_scale = (dem_scale-dem_min)/(dem_max-dem_min)\n",
    "    return dem_scale, dem_max,dem_min\n",
    "\n",
    "#drop data prior to \n",
    "temp_mat,tmax,tmin=make_temptime_data(temp[:Ntest)\n",
    "dem_mat,dmax,dmin=scale_demand(dem)\n",
    "\n",
    "Nt=len(dem)\n",
    "Ntest = Nt//2\n",
    "\n",
    "temp_train = temp_mat[0:Ntest,:]\n",
    "temp_test = temp_mat[Ntest:,:]\n",
    "dem_train = dem_mat[0:Ntest]\n",
    "dem_test = dem_mat[Ntest:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So strictly speaking, the scaling should be chosen solely from the training data, and then applied to the testing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20216, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def get_random_batch(X,y,n_batch,seq_len):\n",
    "    \"\"\"get_random_batch(Xsig,t,n_batch)   \n",
    "    Gets multiple random samples for the data.\n",
    "    Samples generated by 'get_selection' function.\n",
    "    Makes list of returned entries.\n",
    "    Then combines together with 'stack' function at the end.\n",
    "\n",
    "    X - matrix of inputs, (Nt, Ninputs)\n",
    "    y - vector of desired outputs (Nt)\n",
    "    n_batch - number of batches\n",
    "    seq_len - length of sequence to extract in each batch\n",
    "\n",
    "    Outputs:\n",
    "    X_batch - random subset of inputs shape (Nbatch,seq_len,Ninputs) \n",
    "    y_batch - corresponding subset of outputs (Nbatch,seq_len)\n",
    "    \"\"\"\n",
    "    Nt,Nin = X.shape\n",
    "    x_list=[]\n",
    "    y_list=[]\n",
    "    for i in range(n_batch):\n",
    "        n0=int(np.random.random()*(Nt-seq_len-1))\n",
    "        x_sub = X[n0:n0+seq_len]\n",
    "        y_sub = y[n0:n0+seq_len]\n",
    "        x_list.append(x_sub)\n",
    "        y_list.append(y_sub)\n",
    "    x_batch=np.stack(x_list,axis=0)\n",
    "    y_batch=np.stack(y_list,axis=0)\n",
    "    y_batch=y_batch.reshape( [n_batch,seq_len,-1])                    \n",
    "    return x_batch,y_batch\n",
    "\n",
    "Xb,yb=get_random_batch(temp_mat,dem_mat,1000,24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "n_steps=24\n",
    "n_inputs=len(temp.iloc[0])+3\n",
    "n_neurons=120\n",
    "n_layers=3\n",
    "n_outputs=1  #number of stations to predict at that time.\n",
    "lr=1E-2\n",
    "np.random.seed(seed=3453)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def make_RNN_cell(n_neurons,fn=tf.nn.relu):\n",
    "    cell=BasicRNNCell(num_units=n_neurons,activation=fn)\n",
    "    return cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on batch  950 :\t 0.00134905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on batch  900 :\t 0.00153049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on batch  850 :\t 0.00146475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on batch  800 :\t 0.00187774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on batch  750 :\t 0.00162251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on batch  700 :\t 0.00157671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on batch  650 :\t 0.00153585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on batch  600 :\t 0.00159368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on batch  550 :\t 0.00179491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on batch  500 :\t 0.00205737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on batch  450 :\t 0.00225957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on batch  400 :\t 0.00255632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on batch  350 :\t 0.0033832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on batch  300 :\t 0.00287184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on batch  250 :\t 0.00393118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on batch  200 :\t 0.00471667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on batch  150 :\t 0.00831685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on batch  100 :\t 0.0122283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on batch  50 :\t 0.0184005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on batch  0 :\t 37.4075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Running this thang\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up graphs:Multi-layer RNN\n"
     ]
    }
   ],
   "source": [
    "#Initial test with code liberally borrowed from ch14 of Geron's \n",
    "#\"Practical Machine Learning with scikit-learn and Tensorflow\"\n",
    "\n",
    "#Makes a single RNN cell, with a fully connected output layer (with no activation on the output).\n",
    "\n",
    "print('setting up graphs:Multi-layer RNN')\n",
    "tf.reset_default_graph()\n",
    "#inputs:  Nobs, with n_steps, and n_inputs per step\n",
    "X = tf.placeholder(tf.float32,[None,n_steps,n_inputs],name='X')\n",
    "#Outputs: n_outputs we want to predict in the future.\n",
    "y = tf.placeholder(tf.float32,[None,n_steps,n_outputs],name='y')\n",
    "\n",
    "#define neural network shape\n",
    "#works:make a list of them.  \n",
    "# cell=BasicRNNCell(num_units=n_neurons,activation=tf.nn.relu)\n",
    "\n",
    "#Make a list of cells to pass along.  \n",
    "cell_list=[]\n",
    "for i in range(n_layers):\n",
    "    cell_list.append(make_RNN_cell(n_neurons,tf.nn.relu))\n",
    "\n",
    "multi_cell=tf.contrib.rnn.MultiRNNCell(cell_list,state_is_tuple=True)\n",
    "#Note that using [cell]*n_layers did not work since that copies the memory location, rather than making\n",
    "#a number of independent copies.\n",
    "rnn_outputs,states=tf.nn.dynamic_rnn(multi_cell,X,dtype=tf.float32)\n",
    "#this maps the number of hidden units to fewer outputs.\n",
    "stacked_rnn_outputs = tf.reshape(rnn_outputs,[-1,n_neurons])\n",
    "stacked_outputs = fully_connected(stacked_rnn_outputs,n_outputs,activation_fn=None)\n",
    "outputs=tf.reshape(stacked_outputs,[-1,n_steps,n_outputs])\n",
    "\n",
    "#define loss (mean-square-error)\n",
    "loss = tf.reduce_mean(tf.square(outputs-y))\n",
    "#define optimization function.\n",
    "optimizer=tf.train.AdamOptimizer(learning_rate=lr)\n",
    "training_op=optimizer.minimize(loss)\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "#Try adding everything by name to a collection to save and restore later\n",
    "tf.add_to_collection('X',X)\n",
    "tf.add_to_collection('y',y)\n",
    "tf.add_to_collection('loss',loss)\n",
    "tf.add_to_collection('pred',outputs)\n",
    "tf.add_to_collection('train',training_op)\n",
    "\n",
    "#compute number correct.\n",
    "print('Loading data')\n",
    "n_iter=1000\n",
    "n_batch=100\n",
    "run_network=True\n",
    "\n",
    "if (run_network==True):\n",
    "    print('Running this thang')\n",
    "    with tf.Session() as sess:\n",
    "        init.run()\n",
    "        for iteration in range(n_iter):\n",
    "            #select random starting point. \n",
    "            X_batch,y_batch=get_random_batch(\n",
    "                            temp_train, dem_train, n_batch, n_steps)\n",
    "\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y:y_batch})\n",
    "            if iteration%50 ==0:\n",
    "                mse =loss.eval(feed_dict={X:X_batch,y:y_batch})\n",
    "                print(\"MSE on batch \",iteration,':\\t',mse)\n",
    "                #save model\n",
    "                saver.save(sess, \"./models/pdx_RNN_model\",\n",
    "                           write_meta_graph=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So multiple tanhs are bad.  A couple ReLU layers seem to work well, but do lead to negative predictions.  Note that in comparisons that the early 2015 data is pretty flaky (like the forecasts are zero, and I had to fix multiple issues in the demand data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def model_predict_whole(Xin,path_str=\"pdx_RNN_model\"):\n",
    "    \"\"\"model_predict_whole(tstart)\n",
    "    Retrieve the outputs of the network for all values of the inputs \n",
    "    \"\"\"\n",
    "    Nt,Nin=Xin.shape\n",
    "    nmax = int(Nt/n_steps)\n",
    "    ytot = np.zeros((Nt,1))\n",
    "    #Note that loading/saving graph is not properly implemented yet.    \n",
    "    #reset graph, and reload saved graph\n",
    "    tf.reset_default_graph()\n",
    "    model_path = \"./models/\"+path_str    \n",
    "    saver = tf.train.import_meta_graph(model_path+\".meta\")\n",
    "    #saver=tf.train.import_meta_graph(full_model_name+'.meta')\n",
    "    #restore graph structure\n",
    "    X=tf.get_collection('X')[0]\n",
    "    y=tf.get_collection('y')[0]\n",
    "    outputs=tf.get_collection('pred')[0]\n",
    "    train_op=tf.get_collection('train_op')[0]\n",
    "    loss=tf.get_collection('loss')[0]\n",
    "    #restores weights etc.\n",
    "    #saver.restore(sess,full_model_name)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        #restore variables\n",
    "        saver.restore(sess,model_path)\n",
    "        for i in range(nmax-1):\n",
    "            n0=n_steps*i\n",
    "            x_sub = Xin[n0:n0+n_steps,:]\n",
    "            x_sub = x_sub.reshape(-1,n_steps,Nin)\n",
    "            y_pred=sess.run(outputs,feed_dict={X:x_sub})\n",
    "            #nn_pred=predict_on_batch(sess,X_batch)            \n",
    "            ytot[n0:n0+n_steps]=y_pred\n",
    "    return ytot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def plot_whole_sample_fit(X,y,ntest,n_steps,path_str=\"pdx_RNN_model\"):\n",
    "    \"\"\"plot_whole_sample_fit\n",
    "\n",
    "    Plot ALL of the predictions of the trained model\n",
    "    on a 'test' set with different noise, and longer\n",
    "    times.  Concatenates the predicted results together.  \n",
    "    \"\"\"\n",
    "    #pull in the inputs, and predictions\n",
    "    Nt, Nin = X.shape\n",
    "    ytot=model_predict_whole(X,path_str)\n",
    "    plt.figure()\n",
    "    #now plot against the test sets defined earlier\n",
    "    plt.plot(np.arange(0,ntest),X[:ntest,0],'b',label='Training')\n",
    "    plt.plot(np.arange(ntest,Nt), X[ntest:,0],'g',label='Test')\n",
    "    plt.plot(np.arange(Nt),ytot,'r',label='Predicted')\n",
    "    plt.plot(np.arange(Nt),dem_mat,label='Real')\n",
    "    plt.legend(loc='right')\n",
    "    plt.show()\n",
    "    return ytot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbb0530ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/pdx_RNN_model\n"
     ]
    }
   ],
   "source": [
    "#n0,x_sub,y_pred=toy_predict(2.5)\n",
    "ytot=plot_whole_sample_fit(temp_mat,dem_mat,Ntest,n_steps,'pdx_RNN_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#convert the RNN output to a pandas time-series\n",
    "pred=pd.Series(((dmax-dmin)*ytot+dmin).reshape(-1),index=dem.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbae2fe0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def rmse(x,y):\n",
    "    z = np.sqrt(np.sum((x-y)*(x-y))/len(x))\n",
    "    return z\n",
    "\n",
    "def mape(x,y):\n",
    "    z = np.mean(np.abs((1-x/y)))\n",
    "    return z\n",
    "\n",
    "plt.plot(dem['2015-11':],pred['2015-11':],'.')\n",
    "plt.xlabel('Actual Demand')\n",
    "plt.ylabel('RNN Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So let's compute some actual figures here: What was the mean error over the training and test periods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast RMSE in training/test      : 174.69476178243696, 84.06011120151884\n",
      "RNN Prediction RMSE in training/test: 111.7127825772051, 134.4575370601223\n"
     ]
    }
   ],
   "source": [
    "nt = len(ytot)//2\n",
    "fore_train_rmse=rmse(fore[:nt],dem[:nt])\n",
    "fore_test_rmse=rmse(fore[nt:],dem[nt:])\n",
    "pred_train_rmse=rmse(pred[:nt],dem[:nt])\n",
    "pred_test_rmse=rmse(pred[nt:],dem[nt:])\n",
    "\n",
    "print(\"Forecast RMSE in training/test      : {}, {}\".format(fore_train_rmse,fore_test_rmse))\n",
    "print(\"RNN Prediction RMSE in training/test: {}, {}\".format(pred_train_rmse,pred_test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Let's also check the mean absolute percentage error, and also compare against a persistence forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast MAPE in training/test      : 0.03083559781902836, 0.025407175204897305\n",
      "Persistence MAPE in training/test   : 0.05668131298764103, 0.05417891849965209\n",
      "RNN Prediction MAPE in training/test: 0.034385709158925734, 0.03882750694951655\n"
     ]
    }
   ],
   "source": [
    "fore_train_mape=mape(fore[:nt],dem[:nt])\n",
    "fore_test_mape=mape(fore[nt:],dem[nt:])\n",
    "\n",
    "pers_train_mape=mape(dem[:nt-24].values,dem[24:nt].values)\n",
    "pers_test_mape=mape(dem[nt:-24].values,dem[nt+24:].values)\n",
    "\n",
    "pred_train_mape=mape(pred[:nt],dem[:nt])\n",
    "pred_test_mape=mape(pred[nt:],dem[nt:])\n",
    "\n",
    "print(\"Forecast MAPE in training/test      : {}, {}\".format(fore_train_mape,fore_test_mape))\n",
    "print(\"Persistence MAPE in training/test   : {}, {}\".format(pers_train_mape,pers_test_mape))\n",
    "print(\"RNN Prediction MAPE in training/test: {}, {}\".format(pred_train_mape,pred_test_mape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So this simple RNN does worse than the actual forecast, but does out perform persistence.  Well, that's at least something.\n",
    "Obviously, this can be greatly improved.  The above is a simple toy model, one input station, one output series for the same set of time.\n",
    "We can play with other architectures, activations, and using more data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbac42c080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "date_slice=slice('2016-12-20','2017-01-02')\n",
    "plt.plot(pred[date_slice],label='pred')\n",
    "plt.plot(dem[date_slice],label='demand')\n",
    "plt.plot(fore[date_slice],label='fore')\n",
    "plt.legend(loc='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2017-10-20 03:00:00    1492.0\n",
       "2017-10-20 04:00:00    1492.0\n",
       "2017-10-20 05:00:00    1492.0\n",
       "2017-10-20 06:00:00    1492.0\n",
       "2017-10-20 07:00:00    1492.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbac4a9b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "date_slice=slice('2017-06-01','2017-08-01')\n",
    "plt.plot(pred[date_slice]/dem[date_slice]-1,label='pred err')\n",
    "plt.plot(fore[date_slice]/dem[date_slice]-1,label='fore err')\n",
    "plt.ylabel('Percentage Error')\n",
    "plt.legend(loc='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So looking at the percentage errors, this model (which currently lacks knowledge of holidays) is messing up on Thanksgiving.  Also the model seems to make opposite errors to the forecast model.  It's probably worth checking that the distribution of errors.  Eyeballing the curves shows that the errors are lowest early in the morning, and highest at midday.  The error signal probably has a significant daily frequency component.\n",
    "\n",
    "Right now this is a 3-layer RNN.  We can extend it to include different cell types, fiddle with the network size, and maybe a different layout.\n",
    "I'm going to retry this in a more modular approach (and for a more general set of code), with multiple inputs, differing sizes, dropout, more efficient loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#from EBA_RNN import EBA_RNN\n",
    "from tf_rnn import recurrent_NN, RNNConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Retrying with module\n",
    "\n",
    "This is going to use similar code in a more OOP framework, and ideally a more powerful, flexible model that can handle time-series of varying lengths, and varying number of input/output variables.\n",
    "\n",
    "Why do that here?  Well, the toy model only treats PGE, and uses the weather from Portland.  Including weather and energy usage from other nearby places may be a better predictor for each ISO's demand. \n",
    "\n",
    "Also, this could then be used to model likely demand from elsewhere.\n",
    "\n",
    "Also: why bother with building a separate object? This is all pretty small.  Well, I found that particularly with a Jupyter Notebook it was\n",
    "easy to lose track of what the status of the variables and graphs was.\n",
    "This neatly encapsulates all of that.  (And is easier to modify later, and better programming practice.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "Nstation=3\n",
    "NISO=1\n",
    "Nextra=2\n",
    "Ninputs=Nstation+NISO+Nextra\n",
    "%pdb off\n",
    "rnn_conf=RNNConfig(Ninputs=Ninputs,Nepoch=5000,Nhidden=20,Nprint=100)\n",
    "RNN=recurrent_NN(rnn_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb5d895390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #5000. Current MSE:1.8405640125274658\n",
      "Total Time taken:219.41894936561584\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dem_train2=dem_train.reshape((len(dem_train),1))\n",
    "RNN.train_graph(temp_train,dem_train2,'models/pdx_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2400\n",
      "2400 2400\n",
      "4800 2400\n",
      "7200 2400\n",
      "9600 2400\n",
      "12000 2400\n",
      "14400 2400\n",
      "16800 2400\n",
      "19200 1008\n",
      "20208 0\n",
      "No entries left.  Breaking loop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/pdx_test-5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%pdb off\n",
    "ytot=RNN.predict_all(temp_mat,'models/pdx_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pred=pd.Series(((dmax-dmin)*ytot+dmin).reshape(-1),index=dem.index)\n",
    "#pred=pd.Series((ytot).reshape(-1),index=dem.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbac42ca58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(pred)\n",
    "plt.plot(dem)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "name": "EBA_RNN.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
