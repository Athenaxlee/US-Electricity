{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Recurrent Neural Network\n",
    "\n",
    "Let's try throwing a neural network at this problem. (This was my ultimate goal all along.)  We'll give input method the day of the week, time of day, day of the year, and temperature.    This first version uses a single recurrent cell, with a linear combination at the end.  This could be enhanced by making deeper networks at both the beginning and end, using a fancier cell (LSTM, GRU).  \n",
    "\n",
    "This desperately needs some regularization (dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from get_weather_data import convert_isd_to_df, convert_state_isd\n",
    "from EBA_util import remove_na, avg_extremes\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "from tensorflow.contrib.rnn import BasicRNNCell,LSTMCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in PDX Frame from file\n"
     ]
    }
   ],
   "source": [
    "#Extend to multiple temperature series\n",
    "try:\n",
    "    df_joint=pd.read_csv('data/pdx_joint.txt',\n",
    "        index_col=0, parse_dates=True)\n",
    "    print('Read in PDX Frame from file')\n",
    "except:\n",
    "    print('Creating PDX DataFrame from scratch')\n",
    "    air_df = pd.read_csv('data/air_code_df.gz')\n",
    "    #Just get the weather station data for cities in Oregon.\n",
    "    df_weather=convert_state_isd(air_df,'OR')\n",
    "    #Select temperature for Portland, OR\n",
    "    #msk1=np.array(df_weather['city']=='Portland')\n",
    "    msk2=np.array(df_weather['state']=='OR')\n",
    "    df_pdx_weath=df_weather.loc[msk2]\n",
    "    #find number of unique station city/state combinations\n",
    "    Nstation = len(df_pdx_weath['city, state'].unique())\n",
    "\n",
    "    #reshape the single temperature column into Nstation copies.  \n",
    "    unique_station=df_pdx_weath['city, state'].unique()\n",
    "    temp_df=pd.DataFrame()\n",
    "    for station in unique_station:\n",
    "        colname=str('Temp-'+station)\n",
    "        temp_df[colname]=df_pdx_weath.loc[df_pdx_weath['city, state']==station,'Temp']\n",
    "\n",
    "    #get electricity data for Portland General Electric\n",
    "    df_eba=pd.read_csv('data/EBA_time.gz',index_col=0,parse_dates=True)\n",
    "    msk=df_eba.columns.str.contains('Portland')\n",
    "    df_pdx=df_eba.loc[:,msk]\n",
    "    #select out demand data\n",
    "    msk1 = df_pdx.columns.str.contains('[Dd]emand') \n",
    "    dem=df_pdx.loc[:,msk1]\n",
    "    #Make a combined Portland Dataframe for demand vs weather.\n",
    "    df_joint=pd.DataFrame(dem)\n",
    "    df_joint=df_joint.join(temp_df)\n",
    "    df_joint = df_joint.rename(columns={df_joint.columns[0]:'Demand',\n",
    "             df_joint.columns[1]:'Forecast'})\n",
    "    df_joint.to_csv('data/pdx_joint.txt')\n",
    "    \n",
    "dem=df_joint['Demand'].copy()\n",
    "temp=df_joint.loc[:,df_joint.columns.str.contains('Temp')].copy()\n",
    "fore=df_joint['Forecast'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extreme values 1. Number of zero values 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NA values 156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extreme values 0. Number of zero values 143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NA values 126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extreme values 0. Number of zero values 138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NA values 181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extreme values 0. Number of zero values 148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "Number of NA values 56\n"
     ]
    }
   ],
   "source": [
    "#clean up data, remove NA\n",
    "#remove NA values, and average extreme values down\n",
    "for y in [temp,dem]:\n",
    "    if len(y.shape)>1:\n",
    "        for i in range(y.shape[1]):\n",
    "            x= y.iloc[:,i]\n",
    "            x = remove_na(x)\n",
    "            y.iloc[:,i] = avg_extremes(x)\n",
    "    else:\n",
    "        x= y\n",
    "        x = remove_na(x)\n",
    "        y = avg_extremes(x)\n",
    "    \n",
    "#if len(temp.shape)>1:\n",
    "#    for i in range(temp.shape[1]):\n",
    "#        x=temp.iloc[:,i]\n",
    "#        x = remove_na(x)\n",
    "#        temp.iloc[:,i] = avg_extremes(x)\n",
    "\n",
    "#temp=remove_na(temp)\n",
    "#temp = avg_extremes(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def make_temptime_data(temp_mat):\n",
    "    \"\"\"make_input_data\n",
    "    Takes input temperature data matrix (for multiple locations),\n",
    "    and extends with extra indices for time of day, day of year, day of week, and holiday. \n",
    "\n",
    "    Input: temp_mat - pandas series of temperatures a location.  \n",
    "    Output: in_mat - scaled matrix of temperatures, and scaled times of day and year.\n",
    "            temp_max - maximum temperature for series (needed to invert transformations?)\n",
    "            temp_min - minimum temperature\n",
    "    \"\"\"\n",
    "    Tind = temp_mat.index\n",
    "    Nt=len(Tind)\n",
    "    hr = Tind.hour.values/(24-1)\n",
    "    #scale length of year\n",
    "    dyear = Tind.dayofyear.values/(365-1+Tind.is_leap_year.astype(int))\n",
    "    dweek = Tind.dayofweek.values/(7-1)\n",
    "    #scale temperature data to so that max/min correspond to [0,1]  \n",
    "    temp_max = temp_mat.max(axis=0)\n",
    "    temp_min = temp_mat.min(axis=0)\n",
    "    temp_mat = (temp_mat-temp_min)/(temp_max-temp_min)\n",
    "    in_mat=np.stack([hr,dweek,dyear]).T\n",
    "    in_mat= np.hstack([temp_mat.values,in_mat])\n",
    "    return in_mat, temp_max,temp_min\n",
    "\n",
    "def scale_demand(dem):\n",
    "    \"\"\"scale_demand\n",
    "    Scale demand to be on 0,1 scale.\n",
    "    Input: demand - series at single location\n",
    "    Output: dem_scale - scaled array of values.\n",
    "            dem_max, dem_min - the maximum and minimum values.\n",
    "    \"\"\"\n",
    "    dem_scale = dem.values\n",
    "    dem_max = np.max(dem_scale)\n",
    "    dem_min = np.min(dem_scale)\n",
    "    dem_scale = (dem_scale-dem_min)/(dem_max-dem_min)\n",
    "    return dem_scale, dem_max,dem_min\n",
    "\n",
    "temp_mat,tmax,tmin=make_temptime_data(temp)\n",
    "dem_mat,dmax,dmin=scale_demand(dem)\n",
    "\n",
    "Nt=len(dem)\n",
    "Ntest = Nt//2\n",
    "\n",
    "temp_train = temp_mat[0:Ntest,:]\n",
    "temp_test = temp_mat[Ntest:,:]\n",
    "dem_train = dem_mat[0:Ntest]\n",
    "dem_test = dem_mat[Ntest:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20216,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dem_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(dem).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def get_random_batch(X,y,n_batch,seq_len):\n",
    "    \"\"\"get_random_batch(Xsig,t,n_batch)   \n",
    "    Gets multiple random samples for the data.\n",
    "    Samples generated by 'get_selection' function.\n",
    "    Makes list of returned entries.\n",
    "    Then combines together with 'stack' function at the end.\n",
    "\n",
    "    X - matrix of inputs, (Nt, Ninputs)\n",
    "    y - vector of desired outputs (Nt)\n",
    "    n_batch - number of batches\n",
    "    seq_len - length of sequence to extract in each batch\n",
    "\n",
    "    Outputs:\n",
    "    X_batch - random subset of inputs shape (Nbatch,seq_len,Ninputs) \n",
    "    y_batch - corresponding subset of outputs (Nbatch,seq_len)\n",
    "    \"\"\"\n",
    "    Nt,Nin = X.shape\n",
    "    x_list=[]\n",
    "    y_list=[]\n",
    "    for i in range(n_batch):\n",
    "        n0=int(np.random.random()*(Nt-seq_len-1))\n",
    "        x_sub = X[n0:n0+seq_len]\n",
    "        y_sub = y[n0:n0+seq_len]\n",
    "        x_list.append(x_sub)\n",
    "        y_list.append(y_sub)\n",
    "    x_batch=np.stack(x_list,axis=0)\n",
    "    y_batch=np.stack(y_list,axis=0)\n",
    "    y_batch=y_batch.reshape( [n_batch,seq_len,-1])                    \n",
    "    return x_batch,y_batch\n",
    "\n",
    "Xb,yb=get_random_batch(temp_mat,dem_mat,1000,24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 24, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "n_steps=24\n",
    "n_inputs=len(temp.iloc[0])+3\n",
    "n_neurons=120\n",
    "n_layers=3\n",
    "n_outputs=1  #number of stations to predict at that time.\n",
    "lr=1E-2\n",
    "np.random.seed(seed=3453)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def make_RNN_cell(n_neurons,fn=tf.nn.relu):\n",
    "    cell=BasicRNNCell(num_units=n_neurons,activation=fn)\n",
    "    return cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 \tMSE: 0.0138508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 \tMSE: 0.0161236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 \tMSE: 0.0143526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 \tMSE: 0.015318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 \tMSE: 0.0219297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 \tMSE: 0.022877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 \tMSE: 0.0254141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 \tMSE: 0.0299337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 \tMSE: 0.0298571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 \tMSE: 0.237012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 \tMSE: 0.448338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 \tMSE: 0.456865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 \tMSE: 0.449538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \tMSE: 0.451826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Running this thang\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up graphs:Multi-layer RNN\n"
     ]
    }
   ],
   "source": [
    "#Initial test with code liberally borrowed from ch14 of Geron's \n",
    "#\"Practical Machine Learning with scikit-learn and Tensorflow\"\n",
    "\n",
    "#Makes a single RNN cell, with a fully connected output layer (with no activation on the output).\n",
    "\n",
    "print('setting up graphs:Multi-layer RNN')\n",
    "tf.reset_default_graph()\n",
    "#inputs:  Nobs, with n_steps, and n_inputs per step\n",
    "X = tf.placeholder(tf.float32,[None,n_steps,n_inputs],name='X')\n",
    "#Outputs: n_outputs we want to predict in the future.\n",
    "y = tf.placeholder(tf.float32,[None,n_steps,n_outputs],name='y')\n",
    "\n",
    "#define neural network shape\n",
    "#works:make a list of them.  \n",
    "# cell=BasicRNNCell(num_units=n_neurons,activation=tf.nn.relu)\n",
    "# cell2=BasicRNNCell(num_units=n_neurons,activation=tf.nn.relu)\n",
    "# multi_cell = tf.contrib.rnn.MultiRNNCell([cell,cell2],state_is_tuple=True)\n",
    "\n",
    "#Make a list of cells to pass along.  \n",
    "cell_list=[]\n",
    "for i in range(n_layers):\n",
    "    cell_list.append(make_RNN_cell(n_neurons,tf.nn.relu))\n",
    "\n",
    "multi_cell=tf.contrib.rnn.MultiRNNCell(cell_list,state_is_tuple=True)\n",
    "#multi_cell = tf.contrib.rnn.MultiRNNCell([cell]*n_layers,state_is_tuple=True)\n",
    "#Note that using [cell]*n_layers did not work.  Might need to change init_state?\n",
    "#Based on \n",
    "rnn_outputs,states=tf.nn.dynamic_rnn(multi_cell,X,dtype=tf.float32)\n",
    "#this maps the number of hidden units to fewer outputs.\n",
    "stacked_rnn_outputs = tf.reshape(rnn_outputs,[-1,n_neurons])\n",
    "stacked_outputs = fully_connected(stacked_rnn_outputs,n_outputs,activation_fn=tf.nn.tanh)\n",
    "outputs=tf.reshape(stacked_outputs,[-1,n_steps,n_outputs])\n",
    "\n",
    "#define loss (mean-square-error)\n",
    "loss = tf.reduce_mean(tf.square(outputs-y))\n",
    "#define optimization function.\n",
    "optimizer=tf.train.AdamOptimizer(learning_rate=lr)\n",
    "training_op=optimizer.minimize(loss)\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "#compute number correct.\n",
    "print('Loading data')\n",
    "n_iter=1000\n",
    "n_batch=100\n",
    "run_network=True\n",
    "\n",
    "if (run_network==True):\n",
    "    print('Running this thang')\n",
    "    with tf.Session() as sess:\n",
    "        init.run()\n",
    "        for iteration in range(n_iter):\n",
    "            #select random starting point. \n",
    "            X_batch,y_batch=get_random_batch(\n",
    "                            temp_train, dem_train, n_batch, n_steps)\n",
    "\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y:y_batch})\n",
    "            if iteration%10 ==0:\n",
    "                mse =loss.eval(feed_dict={X:X_batch,y:y_batch})\n",
    "                print(iteration,\"\\tMSE:\",mse)\n",
    "                #save model\n",
    "                saver.save(sess, \"./models/pdx_RNN_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'a', 'a']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 \tMSE: 0.0305145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \tMSE: 0.0704299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up graphs: Hidden-RNN-Hidden\n"
     ]
    }
   ],
   "source": [
    "#Add a hidden layer on input/output to simple RNN cell\n",
    "n_steps=24\n",
    "n_inputs=len(temp.iloc[0])+3\n",
    "n_hidden=100\n",
    "n_outputs=24\n",
    "\n",
    "print('setting up graphs: Hidden-RNN-Hidden')\n",
    "tf.reset_default_graph()\n",
    "\n",
    "tf.reset_default_graph()\n",
    "#inputs:  Nobs, with n_steps, and n_inputs per step\n",
    "X = tf.placeholder(tf.float32,[None,n_steps,n_inputs],name='X')\n",
    "#Outputs: n_outputs we want to predict in the future.\n",
    "y = tf.placeholder(tf.float32,[None,n_steps,n_outputs],name='y')\n",
    "\n",
    "#define neural network shape\n",
    "cell=BasicRNNCell(num_units=n_neurons,activation=tf.nn.relu)\n",
    "rnn_outputs,states=tf.nn.dynamic_rnn(cell,X,dtype=tf.float32)\n",
    "#this maps the number of hidden units to fewer outputs.\n",
    "stacked_rnn_outputs = tf.reshape(rnn_outputs,[-1,n_neurons])\n",
    "stacked_outputs = fully_connected(stacked_rnn_outputs,n_outputs,activation_fn=tf.nn.tanh)\n",
    "outputs=tf.reshape(stacked_outputs,[-1,n_steps,n_outputs])\n",
    "\n",
    "\n",
    "#define loss (mean-square-error)\n",
    "loss = tf.reduce_mean(tf.square(output_2-y))\n",
    "#define optimization function.\n",
    "optimizer=tf.train.AdamOptimizer(learning_rate=lr)\n",
    "training_op=optimizer.minimize(loss)\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "n_iter=20\n",
    "n_batch=100\n",
    "\n",
    "##make model saver\n",
    "#Old\n",
    "saver = tf.train.Saver()\n",
    "save_path=\"./models/pdx_RNN2_model\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "     init.run()\n",
    "     for iteration in range(n_iter):\n",
    "         #select random starting point. \n",
    "         X_batch,y_batch=get_random_batch(\n",
    "         temp_train, dem_train, n_batch, n_steps)\n",
    "         sess.run(training_op, feed_dict={X: X_batch, y:y_batch})\n",
    "         if iteration%10 ==0:\n",
    "            mse =loss.eval(feed_dict={X:X_batch,y:y_batch})\n",
    "            print(iteration,\"\\tMSE:\",mse)\n",
    "            #save model\n",
    "            saver.save(sess, save_path)\n",
    "\n",
    "exported_meta=tf.train.export_meta_graph( filename=save_path+\".meta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def model_predict_whole(Xin,path_str=\"pdx_RNN_model\"):\n",
    "    \"\"\"model_predict_whole(tstart)\n",
    "    Retrieve the outputs of the network for all values of the inputs \n",
    "    \"\"\"\n",
    "    Nt,Nin=Xin.shape\n",
    "    nmax = int(Nt/n_steps)\n",
    "    ytot = np.zeros((Nt,1))\n",
    "    #reset graph, and reload saved graph\n",
    "    #tf.reset_default_graph()\n",
    "    model_path = \"./models/\"+path_str    \n",
    "    #saver = tf.train.import_meta_graph(model_path+\".meta\")        \n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        #restore variables\n",
    "        saver.restore(sess,model_path)\n",
    "        for i in range(nmax-1):\n",
    "            n0=n_steps*i\n",
    "            x_sub = Xin[n0:n0+n_steps,:]\n",
    "            x_sub = x_sub.reshape(-1,n_steps,Nin)\n",
    "            y_pred=sess.run(outputs,feed_dict={X:x_sub})\n",
    "            ytot[n0:n0+n_steps]=y_pred\n",
    "    return ytot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def plot_whole_sample_fit(X,y,ntest,n_steps,path_str=\"pdx_RNN_model\"):\n",
    "    \"\"\"plot_whole_sample_fit\n",
    "\n",
    "    Plot ALL of the predictions of the trained model\n",
    "    on a 'test' set with different noise, and longer\n",
    "    times.  Concatenates the predicted results together.  \n",
    "    \"\"\"\n",
    "    #pull in the inputs, and predictions\n",
    "    Nt, Nin = X.shape\n",
    "    ytot=model_predict_whole(X,path_str)\n",
    "    plt.figure()\n",
    "    #now plot against the test sets defined earlier\n",
    "    plt.plot(np.arange(0,ntest),X[:ntest,0],'b',label='Training')\n",
    "    plt.plot(np.arange(ntest,Nt), X[ntest:,0],'g',label='Test')\n",
    "    plt.plot(np.arange(Nt),ytot,'r',label='Predicted')\n",
    "    plt.plot(np.arange(Nt),dem_mat,label='Real')\n",
    "    plt.legend(loc='right')\n",
    "    plt.show()\n",
    "    return ytot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb9f02f940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/pdx_RNN_model\n"
     ]
    }
   ],
   "source": [
    "#n0,x_sub,y_pred=toy_predict(2.5)\n",
    "ytot=plot_whole_sample_fit(temp_mat,dem_mat,Ntest,n_steps,'pdx_RNN_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%pdb off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pred=pd.DataFrame(ytot,index=dem.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20216, 1)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbac0ebbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def rmse(x,y):\n",
    "    z = np.sqrt(np.sum((x-y)*(x-y))/len(x))\n",
    "    return z\n",
    "\n",
    "plt.plot(fore,ytot,'.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0303363570153\n",
      "0.149862419879\n"
     ]
    }
   ],
   "source": [
    "print(rmse(fore['2016-01':'2016-06']/dem['2016-01':'2016-06'],1))\n",
    "nt = len(ytot)//2\n",
    "print(rmse(pred[:nt],dem_mat[:nt]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "len(ytot)//2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "name": "EBA_RNN.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
