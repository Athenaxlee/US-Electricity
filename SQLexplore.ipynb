{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Overview of Electricity Generation in the USA based on EIA data\n",
    "\n",
    "The following is an exercise in using data from the Electricity Information Agency (EIA),\n",
    "to famialarize myself with both the broad state of the US electrical grid, as well as some elementary data science.\n",
    "\n",
    "I have converted the bulk data file from (url_here) to a local SQL database.  I used Psycopg2 for direct SQL interaction with that PostGRESQL database.  \n",
    "I can then efficiently select data from that database, based on geographic region and type of generation.  (While the data should nominally fit into memory in one Pandas dataframe, I found that my computer ran out of memory before it could be loaded.)  \n",
    "\n",
    "The resulting queries from SQL can then be converted into a Pandas dataframe.  Since the data is of the form\n",
    "\"[[date1,number1],[date2,number]...], as one long string, this is converted into a list, then a Numpy array.\n",
    "The first column is used to generate a Pandas PeriodIndex (which is then further converted to a DateTimeIndex for plotting reasons).  The second column is then indexed.  The resulting series is output as the elements of a list of series for the desired state, and generation type.  \n",
    "These results can then be plotted using basic Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy\n",
    "import psycopg2\n",
    "import datetime \n",
    "import matplotlib.pyplot as pl\n",
    "from psycopg2 import sql\n",
    "from mpl_toolkits.basemap import Basemap  #mapping utility\n",
    "import pickle   #Useful for caching maps\n",
    "\n",
    "#from sql_lib import create_conn_and_cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Set up connections to SQL database, which was generated from the bulk JSON file.\n",
    "database_name='US_ELEC'\n",
    "fname='ELEC'\n",
    "table_name=fname\n",
    "engine=sqlalchemy.create_engine(\"postgresql+psycopg2://localhost/\"+database_name)\n",
    "\n",
    "#make connection to database (which is needed by Pandas), \n",
    "# and the cursor which actually executes SQL commands.\n",
    "conn=psycopg2.connect(dbname=database_name,host='localhost')\n",
    "conn.set_session(autocommit=True)\n",
    "cur = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The following defines some useful functions for grabbing SQL queries, and loading the desired columns into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#make safe SQL queries, with deired list of columns in \"out_columns\".\n",
    "#Assume we are searching through name for entries with desired type of series, for particular states,\n",
    "#as well as generation type.\n",
    "def safe_sql_query(table_name, out_columns, match_names, freq):\n",
    "    col_query=sql.SQL(' ,').join(map(sql.Identifier,out_columns))\n",
    "    #make up categories to match the name by.\n",
    "    namelist=[];\n",
    "    for namevar in match_names:\n",
    "        namelist.append(sql.Literal('%'+namevar+'%'))\n",
    "        #join together these matches with ANDs to match them all\n",
    "        name_query=sql.SQL(' AND name LIKE ').join(namelist)\n",
    "    #Total SQL query to select desired columns with features \n",
    "    q1 = sql.SQL(\"SELECT {} FROM {} WHERE (name LIKE {} AND f LIKE {}) \").format(\n",
    "        col_query,\n",
    "        sql.Identifier(table_name),\n",
    "        name_query,\n",
    "        sql.Literal(freq))\n",
    "    return(q1)\n",
    "\n",
    "# def safe_elec_sql_query(table_name,\n",
    "#                    out_columns,\n",
    "#                    series_type='Net generation', \n",
    "#                    state='Oregon',\n",
    "#                    sector='all sectors',\n",
    "#                    gen_type='hydro',\n",
    "#                    freq='M'):\n",
    "#     #make up categories to match the name by. \n",
    "#     l1 = sql.Literal(series_type+' :%')\n",
    "#     l2 = sql.Literal('%: '+state+' :%')\n",
    "#     l3 = sql.Literal('%'+gen_type+'%')\n",
    "#     l4 = sql.Literal('%'+sector+'%')\n",
    "#     #join together these matches with ANDs to match them all\n",
    "#     like_query=sql.SQL(' AND name LIKE ').join([l1,l2,l3,l4])\n",
    "\n",
    "#     #Total SQL query to select desired columns with features \n",
    "#     q1 = sql.SQL(\"SELECT {} FROM {} WHERE (name LIKE {} AND f LIKE {}) \").format(\n",
    "#                 sql.SQL(' ,').join(map(sql.Identifier,out_columns)),\n",
    "#                 sql.Identifier(table_name),\n",
    "#                 like_query,\n",
    "#                 sql.Literal(freq))\n",
    "#     return(q1)\n",
    "\n",
    "#Get a dataframe from SQL database for given psycopg2 cursor,\n",
    "#with desired output columns.     \n",
    "#Must select data based on series type, state, and type of generation.\n",
    "def get_dataframe(cur, table_name, out_columns, match_names, freq):\n",
    "    q = safe_sql_query(table_name,out_columns,match_names,freq)\n",
    "    cur.execute(q);\n",
    "    df0=cur.fetchall();\n",
    "    df = pd.DataFrame(df0,columns=out_columns);\n",
    "    return df\n",
    "\n",
    "# def get_elec_dataframe(cur,\n",
    "#                   out_columns,\n",
    "#                   table=\"ELEC\",\n",
    "#                   series_type='Net Generation',\n",
    "#                   state='Oregon',\n",
    "#                   sector='all sectors',\n",
    "#                   gen_type='solar',\n",
    "#                   freq='M'):\n",
    "#     q = safe_elec_sql_query(table,out_columns,series_type=series_type,state=state,sector=sector,gen_type=gen_type,freq=freq)\n",
    "#     cur.execute(q);\n",
    "#     df0=cur.fetchall();\n",
    "#     df = pd.DataFrame(df0,columns=out_columns);\n",
    "#     return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Initial readin of SQL dataframes returns 'data' as a string of a list of lists.  \n",
    "#This function goes row by row, converting that 'data' column\n",
    "#into a new series, with datetimeindex in 'data2'\n",
    "\n",
    "# Make a Period Index - really, really easy.\n",
    "#But plotting is limited with \"Periods\".  It seems only\n",
    "#\"DateTimeIndices\" allow easy combinations.  Use to_timestamp to convert to a DatetimeIndex.\n",
    "def convert_data(df):\n",
    "    Nrows=len(df)\n",
    "    print(Nrows)\n",
    "    data_array=[];\n",
    "    for i in range(0,Nrows):\n",
    "        #check there's actually data there.\n",
    "        #use next line since the read in dataframe has returned a string.\n",
    "        print('Converting #',i)\n",
    "        init_series=np.asarray(eval(df.iloc[i]['data']))\n",
    "        dat2=init_series[:,1];\n",
    "        f = df.iloc[i]['f']\n",
    "        periodindex=pd.PeriodIndex(init_series[:,0],freq=f)\n",
    "        s=pd.Series(dat2,index=periodindex)\n",
    "        data_array.append(s.to_timestamp())\n",
    "    return data_array\n",
    "\n",
    "# def convert_data(df):\n",
    "#     Nrows=len(df)\n",
    "# # df['data2']=pd.Series()\n",
    "#     data_array=[];\n",
    "#     for i in range(0,Nrows):\n",
    "#         #check there's actually data there.\n",
    "#         #use next line since the read in dataframe has returned a string.\n",
    "#         init_series=np.asarray(eval(df.loc[i,'data']))\n",
    "#         dat2=init_series[:,1];\n",
    "#         f = df.loc[i,'f']\n",
    "#         periodindex=pd.PeriodIndex(init_series[:,0],freq=f)\n",
    "#         s=pd.Series(dat2,index=periodindex)\n",
    "#         data_array.append(s.to_timestamp())\n",
    "# #        df['data2']=data_array\n",
    "# #        df.loc[i,'data2']=data_array[i]\n",
    "#     return data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Try to select data from fields with names such as net generation and desired state.\n",
    "#Possibly also by electricity source.  Nuclear/Solar/Wind/Gas/Coal etc.  \n",
    "#Useful fields: Net Generation : state : type\n",
    "#Also interesting: Average retail price of electricity.  \n",
    "#Net generation\n",
    "#Retail sales of electricity\n",
    "#Revenue\n",
    "#Can Identify useful tags by splitting at colons\":\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Make list of states\n",
    "states=('Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut', 'Delaware', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## United States Seasonal Variation\n",
    "\n",
    "Let's now survey the seasonal variations in the major sources of generation for the United States as a whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Converting # 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Converting # 0\n",
      "Getting hydro\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Converting # 0\n",
      "Converting # 1\n",
      "Getting wind\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Converting # 0\n",
      "Getting solar\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Converting # 0\n",
      "Getting natural gas\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Getting coal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting nuclear\n"
     ]
    }
   ],
   "source": [
    "out_col=('name','data','start','end','f')\n",
    "df_tot=pd.DataFrame()\n",
    "\n",
    "for gen_type in ('nuclear','coal','natural gas','solar','wind','hydro'):\n",
    "    #for name in ('solar','wind','hydro', 'bio'):\n",
    "    print('Getting '+gen_type);\n",
    "    match_names=['Net generation',': Oregon :',gen_type, ': all sectors :'];\n",
    "    df=get_dataframe(cur,'ELEC',out_col,match_names,freq='M');\n",
    "    data0=convert_data(df)\n",
    "    df['data2']=data0\n",
    "    df_tot=df_tot.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbc2eee470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(0,len(df_tot)):\n",
    "    pl.plot(df_tot.iloc[i]['data2'],label=df_tot.iloc[i]['name'])\n",
    "pl.legend(loc='upper left',bbox_to_anchor=(1,1))\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Evidently coal, natural gas and nuclear power provide the vast majority of the US's electrical supply.\n",
    "While coal us is declining (the decline starts in 2008, perhaps Obama or appointee's policies emphasizing cleaner energy?),\n",
    "that decline is matched by an increase in the use of natural gas.  \n",
    "Nuclear power is fairly stable.  No new capacity, since the public has an irrational distaste for nuclear power (or is at least deeply suspicious that nuclear power will be safely managed).\n",
    "It seems that coal and natural gas have the largest seasonal spikes. Coal seems to have spikes in both summer and winter, while natural gas spikes only in summer?\n",
    "\n",
    "Of the renewables, solar and wind are the dominant providers.  Solar capacity has been approximately constant, while the supply of wind-based electricity generation has been growing over the last decade.  \n",
    "I think this data does not capture home-owner installed solar, with selling electricity back to the grid.\n",
    "The other sources, such as hydro and biomass are a small part of the whole.\n",
    "Note that these are all monthly averages.  These do not capture the short scale fluctuations that can occur on the minute to hour timescale which can impact the usefulness of renewables.  (This variability would to be the obvious reason to invest in energy storage: it can act as a ratchet to capture this fluctuating energy source, and store it in a dependable form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Cost of Electricity\n",
    "\n",
    "Another data set is the price of electricity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Geographic variability in 2016\n",
    "\n",
    "Time to break out some Matplotlib.baseplot goodness for plots of the US.\n",
    "(This is also directly relevant to the data available from the EIA, since the US is broken into 5 major power regions,\n",
    "which then interact by buying and selling electricity from one another.)\n",
    "Using annual data, which states use the most electricity of each type?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Fine BaseMap and storing with pickle\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5c9d352518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# try:\n",
    "# \t#Check if pickled(saved) Basemap instance is available - saves lots of time\n",
    "# \tm=pickle.load(open('usstates.pickle','rb'))\n",
    "# \tprint('Loading Map from pickle')\n",
    "# except:\n",
    "\t#if not, remake the Basemap (costs lots of time)\n",
    "pl.figure()  \n",
    "print('Creating Fine BaseMap and storing with pickle')\n",
    "m=Basemap(projection='merc',llcrnrlon=-130,llcrnrlat=25,\\\n",
    "\t\t\t\t\turcrnrlon=-65,urcrnrlat=50,resolution='l', \\\n",
    "\t\t\t\t\tlon_0=-115, lat_0=35)\n",
    "m.drawstates()\n",
    "m.drawcountries()\n",
    "#\tpickle.dump(m,open('map.pickle','wb'),-1)\n",
    "#actually draw the map\n",
    "m.drawcoastlines()\n",
    "pl.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Near Real-time data.\n",
    "\n",
    "Now to load in some of the actual operating data (which is in a different table in the same database).\n",
    "Ok, that is not really working, since I screwed up loading the data into the database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "database_name='US_ELEC'\n",
    "fname='EBA'\n",
    "table_name=fname\n",
    "engine2=sqlalchemy.create_engine(\"postgresql+psycopg2://localhost/\"+database_name)\n",
    "#make connection to database (which is needed by Pandas), \n",
    "# and the cursor which actually executes SQL commands.\n",
    "conn2=psycopg2.connect(dbname=database_name,host='localhost')\n",
    "conn2.set_session(autocommit=True)\n",
    "cur2 = conn2.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#make safe SQL queries, with deired list of columns in \"out_columns\".\n",
    "#Assume we are searching through name for entries with desired type of series, for particular states,\n",
    "#as well as generation type.\n",
    "# def safe_eba_sql_query(table_name,\n",
    "#                    out_columns,\n",
    "#                    series_type='Demand', \n",
    "#                    region='Northwest',\n",
    "#                    freq='H'):\n",
    "#     #make up categories to match the name by. \n",
    "#     l1 = sql.Literal('%'+series_type+'%')\n",
    "#     l2 = sql.Literal('%'+region+'%')\n",
    "#     #join together these matches with ANDs to match them all\n",
    "#     like_query=sql.SQL(' AND name LIKE ').join([l1,l2])\n",
    "\n",
    "#     #Total SQL query to select desired columns with features \n",
    "#     q1 = sql.SQL(\"SELECT {} FROM {} WHERE (name LIKE {} AND f LIKE {}) \").format(\n",
    "#                 sql.SQL(' ,').join(map(sql.Identifier,out_columns)),\n",
    "#                 sql.Identifier(table_name),\n",
    "#                 like_query,\n",
    "#                 sql.Literal(freq))\n",
    "#     return(q1)\n",
    "\n",
    "# #Get a dataframe from SQL database for given psycopg2 cursor,\n",
    "# #with desired output columns.     \n",
    "# #Must select data based on series type, state, and type of generation.\n",
    "# def get_eba_dataframe(cur,\n",
    "#                   out_columns,\n",
    "#                   table=\"EBA\",\n",
    "#                   series_type='Demand',\n",
    "#                   region='Northwest',\n",
    "#                   freq='H'):\n",
    "#     q = safe_eba_sql_query(table,out_columns,series_type=series_type,region=region,freq=freq)\n",
    "#     cur.execute(q);\n",
    "#     df0=cur.fetchall();\n",
    "#     df = pd.DataFrame(df0,columns=out_columns);\n",
    "#     return df\n",
    "\n",
    "\n",
    "# # Make a Period Index - really, really easy.\n",
    "# #But plotting is limited with \"Periods\".  It seems only\n",
    "# #\"DateTimeIndices\" allow easy combinations.  Use to_timestamp to convert to a DatetimeIndex.\n",
    "# def convert_eba_data(df):\n",
    "#     Nrows=len(df)\n",
    "#     data_array=[];\n",
    "#     for i in range(0,Nrows):\n",
    "#         #check there's actually data there.\n",
    "#         #use next line since the read in dataframe has returned a string.\n",
    "#         init_series=np.asarray(df.iloc[i]['data'])\n",
    "#         dat2=init_series[:,1];\n",
    "#         f = df.iloc[i,'f']\n",
    "#         periodindex=pd.PeriodIndex(init_series[:,0],freq=f)\n",
    "#         s=pd.Series(dat2,index=periodindex)\n",
    "#         data_array.append(s.to_timestamp())\n",
    "#     return data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Northwest:Interchange\n",
      "Getting Northwest:Demand\n",
      "Getting Northwest:Net generation\n"
     ]
    }
   ],
   "source": [
    "#Read in some representative data.\n",
    "out_col=('name','data','start','end','f')\n",
    "df_eba_tot=pd.DataFrame()\n",
    "region='Northwest (region)'\n",
    "#for name in ('Northwest','Southwest','Southeast','Northeast','Central'):\n",
    "for gen_type in ('Net generation','Demand','demand forecast','Interchange'):\n",
    "    print('Getting '+name+':'+type1);\n",
    "    match_name=[gen_type,region];\n",
    "    df=get_dataframe(cur2,table_name='EBA',out_col,match_name,freq='H');\n",
    "    data0=convert_data(df)\n",
    "    df['data2']=data0\n",
    "    df_eba_tot=df_eba_tot.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_eba=pd.read_json('data/split_data/EBA00',lines=True)\n",
    "#df0=df_eba.loc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "?data0[0][0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Finally (months after I first wanted to do this), we can start looking at some data.  \n",
    "I would like to review the sources of electricity to get a sense of seasonal variations (in terms of availability and use).  For example, I'd expect solar generation to be largest in summer, lowest in winter.  \n",
    "I would assume this varies geographically.  I'll assume the seasonality can be averaged over by using the annual data. \n",
    "\n",
    "Residential Use will be largest in winter, barring the occasional fluctuation in summer.  \n",
    "\n",
    "The purpose of this survey is to identify the scale of renewables in the market.  \n",
    "How large a share do renewables (solar, hydro, wind) take up?  How does this vary regionally?  Over time? \n",
    "Who are the primary users of electricity?  \n",
    "I'll assume the base load is provided by coal, gas and nuclear plants.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Ultimately however, I intend to try my hand at some machine learning projects relevant to electricity.  \n",
    "The first project involves demand forecasting.  The other place where data science (and nifty math) may have a role in this, is on the market.  While I am comfortable with stochastic calculus etc, I would need to learn about options pricing\n",
    "and the relevant techniques for this sector of the energy market.\n",
    "\n",
    "This is meant to be a brief background piece for that.  Since we are forecasting a time series,\n",
    "I aim to use TensorFlow with some form of neural network (perhaps recurrent) to try forecasting.\n",
    "Ideally, I would cross-reference the electricity data sets against the published weather forecasts for a given day.  \n",
    "The model should be able to predict demand given the location, time of year, and weather forecast.  (This is probably the \n",
    "simplest thing available)\n",
    "\n",
    "From a smart-grid perspective, how can randomly fluctuating sources, such as solar and wind, be included \n",
    "in supplying power to the grid?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  },
  "name": "SQLexplore.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
