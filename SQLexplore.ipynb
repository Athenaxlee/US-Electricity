{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Overview of Electricity Generation in the USA based on EIA data\n",
    "\n",
    "The following is an exercise in using data from the Electricity Information Agency (EIA),\n",
    "to famialarize myself with both the broad state of the US electrical grid, as well as some elementary data science.\n",
    "\n",
    "I have converted the bulk data file from (url_here) to a local SQL database.  I used Psycopg2 for direct SQL interaction with that PostGRESQL database.  \n",
    "I can then efficiently select data from that database, based on geographic region and type of generation.  (While the data should nominally fit into memory in one Pandas dataframe, I found that my computer ran out of memory before it could be loaded.)  \n",
    "\n",
    "The resulting queries from SQL can then be converted into a Pandas dataframe.  Since the data is of the form\n",
    "\"[[date1,number1],[date2,number]...], as one long string, this is converted into a list, then a Numpy array.\n",
    "The first column is used to generate a Pandas PeriodIndex (which is then further converted to a DateTimeIndex for plotting reasons).  The second column is then indexed.  The resulting series is output as the elements of a list of series for the desired state, and generation type.  \n",
    "These results can then be plotted using basic Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy\n",
    "import psycopg2\n",
    "import datetime \n",
    "import matplotlib.pyplot as pl\n",
    "from psycopg2 import sql\n",
    "\n",
    "from sql_lib import create_conn_and_cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Set up connections to SQL database, which was generated from the bulk JSON file.\n",
    "database_name='US_ELEC'\n",
    "fname='ELEC'\n",
    "table_name=fname\n",
    "engine=sqlalchemy.create_engine(\"postgresql+psycopg2://localhost/\"+database_name)\n",
    "\n",
    "#make connection to database (which is needed by Pandas), \n",
    "# and the cursor which actually executes SQL commands.\n",
    "conn=psycopg2.connect(dbname=database_name,host='localhost')\n",
    "conn.set_session(autocommit=True)\n",
    "cur = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The following defines some useful functions for grabbing SQL queries, and loading the desired columns into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#make safe SQL queries, with deired list of columns in \"out_columns\".\n",
    "#Assume we are searching through name for entries with desired type of series, for particular states,\n",
    "#as well as generation type.\n",
    "def safe_sql_query(table_name,\n",
    "                   out_columns,\n",
    "                   series_type='Net generation', \n",
    "                   state='Oregon',\n",
    "                   sector='all sectors',\n",
    "                   gen_type='hydro',\n",
    "                   freq='M'):\n",
    "    #make up categories to match the name by. \n",
    "    query_match_list=list()\n",
    "    l1 = sql.Literal(series_type+' :%')\n",
    "    l2 = sql.Literal('%: '+state+' :%')\n",
    "    l3 = sql.Literal('%'+gen_type+'%')\n",
    "    l4 = sql.Literal('%'+sector+'%')\n",
    "    #join together these matches with ANDs to match them all\n",
    "    like_query=sql.SQL(' AND name LIKE ').join([l1,l2,l3,l4])\n",
    "\n",
    "    #Total SQL query to select desired columns with features \n",
    "    q1 = sql.SQL(\"SELECT {} FROM {} WHERE (name LIKE {} AND f LIKE {}) \").format(\n",
    "                sql.SQL(' ,').join(map(sql.Identifier,out_columns)),\n",
    "                sql.Identifier(table_name),\n",
    "                like_query,\n",
    "                sql.Literal(freq))\n",
    "\n",
    "    return(q1)\n",
    "\n",
    "#Get a dataframe from SQL database for given psycopg2 cursor,\n",
    "#with desired output columns.     \n",
    "#Must select data based on series type, state, and type of generation.\n",
    "def get_dataframe(cur,\n",
    "                  out_columns,\n",
    "                  table=\"ELEC\",\n",
    "                  series_type='Net Generation',\n",
    "                  state='Oregon',\n",
    "                  sector='all sectors',\n",
    "                  gen_type='solar',\n",
    "                  freq='M'):\n",
    "    q = safe_sql_query(table,out_columns,series_type=series_type,state=state,sector=sector,gen_type=gen_type,freq=freq)\n",
    "    cur.execute(q);\n",
    "    df0=cur.fetchall();\n",
    "    df = pd.DataFrame(df0,columns=out_columns);\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Initial readin of SQL dataframes returns 'data' as a string of a list of lists.  \n",
    "#This function goes row by row, converting that 'data' column\n",
    "#into a new series, with datetimeindex in 'data2'\n",
    "\n",
    "# def convert_df(df):\n",
    "#     Nrows=len(df)\n",
    "# # df['data2']=pd.Series()\n",
    "#     data_array=[];\n",
    "#     for i in range(0,Nrows):\n",
    "#         #check there's actually data there.\n",
    "#         print('Making',i,'dataset')\n",
    "#         #use next line since the read in dataframe has returned a string.\n",
    "#         init_series=np.asarray(eval(df.loc[i,'data']))\n",
    "#         dat2=init_series[:,1];\n",
    "#         timeindex=make_timeindex(df.loc[i])\n",
    "#         if (len(dat2) != len(timeindex)):\n",
    "#             print('Unequal lengths')\n",
    "#             print(len(dat2),len(timeindex))\n",
    "#         else:\n",
    "#             s=pd.Series(dat2,index=timeindex)\n",
    "#             data_array.append(s)\n",
    "\n",
    "#         return data_array\n",
    "\n",
    "    \n",
    "# Make a Period Index - really, really easy.\n",
    "#But plotting is limited with \"Periods\".  It seems only\n",
    "#\"DateTimeIndices\" allow easy combinations.  \n",
    "def convert_df(df):\n",
    "    Nrows=len(df)\n",
    "# df['data2']=pd.Series()\n",
    "    data_array=[];\n",
    "    for i in range(0,Nrows):\n",
    "        #check there's actually data there.\n",
    "        print('Making',i,'dataset')\n",
    "        #use next line since the read in dataframe has returned a string.\n",
    "        init_series=np.asarray(eval(df.loc[i,'data']))\n",
    "        dat2=init_series[:,1];\n",
    "        f = df.loc[i,'f']\n",
    "        periodindex=pd.PeriodIndex(init_series[:,0],freq=f)\n",
    "        s=pd.Series(dat2,index=periodindex)\n",
    "        data_array.append(s.to_timestamp())\n",
    "\n",
    "    return data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making 0 dataset\n"
     ]
    }
   ],
   "source": [
    "#Try to select data from fields with names such as net generation and desired state.\n",
    "#Possibly also by electricity source.  Nuclear/Solar/Wind/Gas/Coal etc.  \n",
    "\n",
    "#Useful fields: Net Generation : state : type\n",
    "#Also interesting: Average retail price of electricity.  \n",
    "#Net generation\n",
    "#Retail sales of electricity\n",
    "#Revenue\n",
    "\n",
    "#Can Identify useful tags by splitting at colons\":\"\n",
    "out_col=('name','data','start','end','f')\n",
    "df=get_dataframe(cur,out_col,series_type='Net generation',state='United States',gen_type='coal');\n",
    "len(df)\n",
    "d0=convert_df(df)\n",
    "df['data2']=d0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2016-10-01     99348.27191\n2016-09-01    114279.66583\n2016-08-01    135808.99792\n2016-07-01    1...\nName: data2, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['data2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbc22c5860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(0,len(d0)):\n",
    "    pl.plot(d0[i],label=df.loc[i,'name'])\n",
    "pl.legend(loc='upper left',bbox_to_anchor=(1,1))\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df['data2']=d0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016-10-01     867.23907\n2016-09-01    1062.51575\n2016-08-01    1425.55774\n2016-07-01    1428.91113\n2016-06-01    1135.71603\n2016-05-01     982.12739\n2016-04-01     819.61795\n2016-03-01    1186.26312\n2016-02-01    1314.56729\n2016-01-01    1460.75627\n2015-12-01    1382.72935\n2015-11-01    1372.23116\n2015-10-01      1438.387\n2015-09-01    1496.14432\n2015-08-01    1657.91515\n2015-07-01    1550.12742\n2015-06-01    1505.57156\n2015-05-01    1361.32943\n2015-04-01    1070.60848\n2015-03-01    1304.99344\n2015-02-01    1573.32056\n2015-01-01     1365.9259\n2014-12-01    1429.56847\n2014-11-01    1552.04534\n2014-10-01    1522.16556\n2014-09-01    1614.24824\n2014-08-01    1823.91512\n2014-07-01     1840.8166\n2014-06-01    1768.58692\n2014-05-01    1515.59692\n                 ...    \n2003-06-01      3015.975\n2003-05-01      2736.742\n2003-04-01      2631.397\n2003-03-01      2927.808\n2003-02-01      3040.436\n2003-01-01      3290.646\n2002-12-01      2719.324\n2002-11-01      2268.341\n2002-10-01      2283.852\n2002-09-01      2537.953\n2002-08-01      2837.973\n2002-07-01      2766.264\n2002-06-01      2550.568\n2002-05-01      2149.421\n2002-04-01      2155.967\n2002-03-01      2490.026\n2002-02-01      2125.629\n2002-01-01      2522.699\n2001-12-01      2595.219\n2001-11-01      2222.914\n2001-10-01      2343.412\n2001-09-01      2625.723\n2001-08-01      2986.154\n2001-07-01      2902.248\n2001-06-01      2803.886\n2001-05-01      2446.183\n2001-04-01      2252.003\n2001-03-01      2385.221\n2001-02-01      2511.426\n2001-01-01      2928.378\nFreq: -1MS, Length: 190, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[3,'data2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Finally (months after I first wanted to do this), we can start looking at some data.  \n",
    "I would like to review the sources of electricity to get a sense of seasonal variations (in terms of availability and use).  For example, I'd expect solar generation to be largest in summer, lowest in winter.  \n",
    "I would assume this varies geographically.  I'll assume the seasonality can be averaged over by using the annual data. \n",
    "\n",
    "Residential Use will be largest in winter, barring the occasional fluctuation in summer.  \n",
    "\n",
    "The purpose of this survey is to identify the scale of renewables in the market.  \n",
    "How large a share do renewables (solar, hydro, wind) take up?  How does this vary regionally?  Over time? \n",
    "Who are the primary users of electricity?  \n",
    "I'll assume the base load is provided by coal, gas and nuclear plants.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Ultimately however, I intend to try my hand at some machine learning projects relevant to electricity.  \n",
    "The first project involves demand forecasting.  The other place where data science (and nifty math) may have a role in this, is on the market.  While I am comfortable with stochastic calculus etc, I would need to learn about options pricing\n",
    "and the relevant techniques for this sector of the energy market.\n",
    "\n",
    "This is meant to be a brief background piece for that.  Since we are forecasting a time series,\n",
    "I aim to use TensorFlow with some form of neural network (perhaps recurrent) to try forecasting.\n",
    "Ideally, I would cross-reference the electricity data sets against the published weather forecasts for a given day.  \n",
    "The model should be able to predict demand given the location, time of year, and weather forecast.  (This is probably the \n",
    "simplest thing available)\n",
    "\n",
    "From a smart-grid perspective, how can randomly fluctuating sources, such as solar and wind, be included \n",
    "in supplying power to the grid?  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  },
  "name": "SQLexplore.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
